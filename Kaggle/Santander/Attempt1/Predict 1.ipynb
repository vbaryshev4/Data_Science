{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import warnings\n",
    "from six.moves import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Data\n",
    "train = pd.read_csv('../Input/train.csv')\n",
    "test = pd.read_csv('../Input/test.csv')\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Model\n",
      "Fold idx:1\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912014\tvalid_1's auc: 0.896374\n",
      "[10000]\ttraining's auc: 0.921895\tvalid_1's auc: 0.900704\n",
      "[15000]\ttraining's auc: 0.929438\tvalid_1's auc: 0.901695\n",
      "[20000]\ttraining's auc: 0.936288\tvalid_1's auc: 0.901691\n",
      "Early stopping, best iteration is:\n",
      "[17286]\ttraining's auc: 0.932616\tvalid_1's auc: 0.901827\n",
      "Fold idx:2\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912139\tvalid_1's auc: 0.895294\n",
      "[10000]\ttraining's auc: 0.922019\tvalid_1's auc: 0.898562\n",
      "[15000]\ttraining's auc: 0.929516\tvalid_1's auc: 0.898838\n",
      "Early stopping, best iteration is:\n",
      "[14139]\ttraining's auc: 0.928286\tvalid_1's auc: 0.898974\n",
      "Fold idx:3\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912446\tvalid_1's auc: 0.889267\n",
      "[10000]\ttraining's auc: 0.922391\tvalid_1's auc: 0.89234\n",
      "[15000]\ttraining's auc: 0.929931\tvalid_1's auc: 0.892466\n",
      "Early stopping, best iteration is:\n",
      "[11740]\ttraining's auc: 0.925134\tvalid_1's auc: 0.892658\n",
      "Fold idx:4\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912619\tvalid_1's auc: 0.900182\n",
      "[10000]\ttraining's auc: 0.922506\tvalid_1's auc: 0.903056\n",
      "Early stopping, best iteration is:\n",
      "[10915]\ttraining's auc: 0.923982\tvalid_1's auc: 0.903282\n",
      "Fold idx:5\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912432\tvalid_1's auc: 0.895919\n",
      "[10000]\ttraining's auc: 0.922339\tvalid_1's auc: 0.898707\n",
      "[15000]\ttraining's auc: 0.929899\tvalid_1's auc: 0.898895\n",
      "Early stopping, best iteration is:\n",
      "[13586]\ttraining's auc: 0.927863\tvalid_1's auc: 0.898973\n",
      "Fold idx:6\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912146\tvalid_1's auc: 0.899038\n",
      "[10000]\ttraining's auc: 0.922039\tvalid_1's auc: 0.901953\n",
      "[15000]\ttraining's auc: 0.929621\tvalid_1's auc: 0.902255\n",
      "Early stopping, best iteration is:\n",
      "[14015]\ttraining's auc: 0.928209\tvalid_1's auc: 0.902347\n",
      "Fold idx:7\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911612\tvalid_1's auc: 0.902827\n",
      "[10000]\ttraining's auc: 0.921537\tvalid_1's auc: 0.905236\n",
      "Early stopping, best iteration is:\n",
      "[10837]\ttraining's auc: 0.922896\tvalid_1's auc: 0.905496\n",
      "Fold idx:8\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912107\tvalid_1's auc: 0.89669\n",
      "[10000]\ttraining's auc: 0.922042\tvalid_1's auc: 0.899542\n",
      "[15000]\ttraining's auc: 0.929588\tvalid_1's auc: 0.899684\n",
      "Early stopping, best iteration is:\n",
      "[13958]\ttraining's auc: 0.928096\tvalid_1's auc: 0.899726\n",
      "Fold idx:9\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912276\tvalid_1's auc: 0.899859\n",
      "[10000]\ttraining's auc: 0.922168\tvalid_1's auc: 0.903057\n",
      "[15000]\ttraining's auc: 0.929667\tvalid_1's auc: 0.903039\n",
      "Early stopping, best iteration is:\n",
      "[11326]\ttraining's auc: 0.924273\tvalid_1's auc: 0.903275\n",
      "Fold idx:10\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911773\tvalid_1's auc: 0.903446\n",
      "[10000]\ttraining's auc: 0.921682\tvalid_1's auc: 0.906464\n",
      "[15000]\ttraining's auc: 0.929219\tvalid_1's auc: 0.906762\n",
      "Early stopping, best iteration is:\n",
      "[15636]\ttraining's auc: 0.930104\tvalid_1's auc: 0.906876\n",
      "Fold idx:11\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911899\tvalid_1's auc: 0.897707\n",
      "[10000]\ttraining's auc: 0.921875\tvalid_1's auc: 0.900628\n",
      "[15000]\ttraining's auc: 0.929447\tvalid_1's auc: 0.900849\n",
      "Early stopping, best iteration is:\n",
      "[12712]\ttraining's auc: 0.926124\tvalid_1's auc: 0.900876\n",
      "CV score: 0.90123 \n"
     ]
    }
   ],
   "source": [
    "num_folds = 11\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "\n",
    "folds = KFold(n_splits=num_folds, random_state=2319)\n",
    "oof = np.zeros(len(train))\n",
    "getVal = np.zeros(len(train))\n",
    "predictions = np.zeros(len(target))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "print('Light GBM Model')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    \n",
    "    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n",
    "    \n",
    "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "    X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "    print(\"Fold idx:{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Submission File\n"
     ]
    }
   ],
   "source": [
    "num_sub = 1\n",
    "print('Saving the Submission File')\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub.to_csv('submission{}.csv'.format(num_sub), index=False)\n",
    "getValue = pd.DataFrame(getVal)\n",
    "getValue.to_csv(\"Validation_kfold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.144885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.276326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.231337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.292443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.060057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "      <td>0.007714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>0.250561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "      <td>0.010668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "      <td>0.344410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>0.047313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "      <td>0.064233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "      <td>0.032231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "      <td>0.009729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>0.049001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>0.412867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "      <td>0.036785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "      <td>0.266616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "      <td>0.015880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "      <td>0.482531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "      <td>0.105382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "      <td>0.011220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "      <td>0.050548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "      <td>0.014627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "      <td>0.148202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "      <td>0.143710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "      <td>0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "      <td>0.393363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "      <td>0.111645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199970</th>\n",
       "      <td>test_199970</td>\n",
       "      <td>0.083550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199971</th>\n",
       "      <td>test_199971</td>\n",
       "      <td>0.197281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199972</th>\n",
       "      <td>test_199972</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199973</th>\n",
       "      <td>test_199973</td>\n",
       "      <td>0.076116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199974</th>\n",
       "      <td>test_199974</td>\n",
       "      <td>0.007412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199975</th>\n",
       "      <td>test_199975</td>\n",
       "      <td>0.110355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>test_199976</td>\n",
       "      <td>0.330960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199977</th>\n",
       "      <td>test_199977</td>\n",
       "      <td>0.280458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>test_199978</td>\n",
       "      <td>0.044683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>test_199979</td>\n",
       "      <td>0.121998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>test_199980</td>\n",
       "      <td>0.099688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199981</th>\n",
       "      <td>test_199981</td>\n",
       "      <td>0.060057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>test_199982</td>\n",
       "      <td>0.037279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>test_199983</td>\n",
       "      <td>0.051140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>test_199984</td>\n",
       "      <td>0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>test_199985</td>\n",
       "      <td>0.212128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "      <td>0.606840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>test_199987</td>\n",
       "      <td>0.067886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>test_199988</td>\n",
       "      <td>0.019434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>test_199989</td>\n",
       "      <td>0.047167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>test_199990</td>\n",
       "      <td>0.006918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>test_199991</td>\n",
       "      <td>0.008105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>test_199992</td>\n",
       "      <td>0.405553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "      <td>0.015396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>test_199994</td>\n",
       "      <td>0.120291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "      <td>0.057261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "      <td>0.010368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>test_199997</td>\n",
       "      <td>0.006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>test_199998</td>\n",
       "      <td>0.140810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "      <td>0.100116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code    target\n",
       "0            test_0  0.144885\n",
       "1            test_1  0.276326\n",
       "2            test_2  0.231337\n",
       "3            test_3  0.292443\n",
       "4            test_4  0.060057\n",
       "5            test_5  0.002710\n",
       "6            test_6  0.007714\n",
       "7            test_7  0.250561\n",
       "8            test_8  0.003400\n",
       "9            test_9  0.010668\n",
       "10          test_10  0.344410\n",
       "11          test_11  0.047313\n",
       "12          test_12  0.064233\n",
       "13          test_13  0.032231\n",
       "14          test_14  0.009729\n",
       "15          test_15  0.049001\n",
       "16          test_16  0.412867\n",
       "17          test_17  0.036785\n",
       "18          test_18  0.266616\n",
       "19          test_19  0.015880\n",
       "20          test_20  0.482531\n",
       "21          test_21  0.105382\n",
       "22          test_22  0.011220\n",
       "23          test_23  0.050548\n",
       "24          test_24  0.014627\n",
       "25          test_25  0.148202\n",
       "26          test_26  0.143710\n",
       "27          test_27  0.022938\n",
       "28          test_28  0.393363\n",
       "29          test_29  0.111645\n",
       "...             ...       ...\n",
       "199970  test_199970  0.083550\n",
       "199971  test_199971  0.197281\n",
       "199972  test_199972  0.006276\n",
       "199973  test_199973  0.076116\n",
       "199974  test_199974  0.007412\n",
       "199975  test_199975  0.110355\n",
       "199976  test_199976  0.330960\n",
       "199977  test_199977  0.280458\n",
       "199978  test_199978  0.044683\n",
       "199979  test_199979  0.121998\n",
       "199980  test_199980  0.099688\n",
       "199981  test_199981  0.060057\n",
       "199982  test_199982  0.037279\n",
       "199983  test_199983  0.051140\n",
       "199984  test_199984  0.019704\n",
       "199985  test_199985  0.212128\n",
       "199986  test_199986  0.606840\n",
       "199987  test_199987  0.067886\n",
       "199988  test_199988  0.019434\n",
       "199989  test_199989  0.047167\n",
       "199990  test_199990  0.006918\n",
       "199991  test_199991  0.008105\n",
       "199992  test_199992  0.405553\n",
       "199993  test_199993  0.015396\n",
       "199994  test_199994  0.120291\n",
       "199995  test_199995  0.057261\n",
       "199996  test_199996  0.010368\n",
       "199997  test_199997  0.006374\n",
       "199998  test_199998  0.140810\n",
       "199999  test_199999  0.100116\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
