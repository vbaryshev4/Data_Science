{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data = requests.get('https://raw.githubusercontent.com/gastonstat/CreditScoring/master/CreditScoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(io.StringIO(data.text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Home</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Records</th>\n",
       "      <th>Job</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Income</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status  Seniority  Home  Time  Age  Marital  Records  Job  Expenses  \\\n",
       "0       1          9     1    60   30        2        1    3        73   \n",
       "1       1         17     1    60   58        3        1    1        48   \n",
       "2       2         10     2    36   46        2        2    3        90   \n",
       "3       1          0     1    60   24        1        1    1        63   \n",
       "4       1          0     1    36   26        1        1    1        46   \n",
       "\n",
       "   Income  Assets  Debt  Amount  Price  \n",
       "0     129       0     0     800    846  \n",
       "1     131       0     0    1000   1658  \n",
       "2     200    3000     0    2000   2985  \n",
       "3     182    2500     0     900   1325  \n",
       "4     107       0     0     310    910  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3200\n",
       "2    1254\n",
       "0       1\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предсказывайте Status 1 (good) vs. Status 2 (bad)\n",
    "# 0 выпилить\n",
    "df.Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Status'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3200\n",
       "2    1254\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df.drop('Status', 1), df['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3200\n",
       "1    1254\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подберите наилучшие гиперпараметры для модели решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   21.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(5, 10)),\n",
    "    'max_features': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'min_samples_leaf': list(range(3, 20))\n",
    "}\n",
    "gs = GridSearchCV(clf, params_grid, scoring='roc_auc', verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=0.7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=14, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выберите наилучшую на Ваш взгляд метрику качества для этой задачи. Объясните свой выбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 76.83%\n"
     ]
    }
   ],
   "source": [
    "'''Accuracy - Accuracy is the most intuitive performance measure \n",
    "and it is simply a ratio of correctly predicted observation to the total observations. \n",
    "One may think that, if we have high accuracy then our model is best. \n",
    "Yes, accuracy is a great measure but only when you have symmetric datasets \n",
    "where values of false positive and false negatives are almost same.\n",
    "\n",
    "Accuracy = TP+TN/TP+FP+FN+TN\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Decision tree accuracy: %.2f%%' % (100 * accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 54.69%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Precision - Precision is the ratio of correctly predicted positive observations \n",
    "to the total predicted positive observations.  \n",
    "High precision relates to the low false positive rate. \n",
    "\n",
    "Precision = TP/TP+FP\n",
    "'''\n",
    "from sklearn.metrics import precision_score\n",
    "print('Decision tree accuracy: %.2f%%' % (100 * precision_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 60.69%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations \n",
    "to the all observations in actual class - yes.  \n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "'''\n",
    "from sklearn.metrics import recall_score\n",
    "print('Decision tree accuracy: %.2f%%' % (100 * recall_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[409,  68],\n",
       "       [ 87, 105]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Let's start with the one popular tools to evaluate the performance of a model \n",
    "in tasks of classification or prediction:  The confusion matrix \n",
    "(in unsupervised learning it is typically called a matching matrix). \n",
    "Its focus is on the predictive capability of a model  rather than how fast \n",
    "the model takes to perform the classification, scalability, etc.\n",
    "\n",
    "The confusion matrix is represented by a matrix which each row represents \n",
    "the instances in a predicted class, while each column represents in an actual class. \n",
    "One of the advantages of using this performance evaluation tool is that \n",
    "the data mining analyzer can easily see if the model is confusing two classes \n",
    "(i.e. commonly  mislabeling one as another).\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[409  68]\n",
      " [ 87 105]]\n",
      "Normalized confusion matrix\n",
      "[[0.86 0.14]\n",
      " [0.45 0.55]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAEYCAYAAAAu+iEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115871dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAEYCAYAAAAnEYFiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq2n/H1rncZK7TfUGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158870f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = [1, 0]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поупражнялись с метриками качества оценки модели, теперь выберем лучшие показатели на разных метриках как гиперпараметр Гридсерча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: accuracy\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=0.7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=16, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 76.53%\n",
      "precision: 48.44%\n",
      "recall: 61.59%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: f1\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features=0.9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=17, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 78.33%\n",
      "precision: 42.19%\n",
      "recall: 70.43%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: neg_log_loss\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=0.9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=19, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 77.73%\n",
      "precision: 45.31%\n",
      "recall: 66.41%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   24.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: precision\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=0.9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 79.82%\n",
      "precision: 45.31%\n",
      "recall: 74.36%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   22.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: r2\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features=0.7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=14, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 78.48%\n",
      "precision: 49.48%\n",
      "recall: 66.90%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: recall\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=0.9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=19, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 78.62%\n",
      "precision: 52.60%\n",
      "recall: 66.01%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING: roc_auc\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=0.5, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=13, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 77.88%\n",
      "precision: 44.27%\n",
      "recall: 67.46%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n",
      "SCORING: v_measure_score\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,\n",
      "            max_features=1.0, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=18, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 78.03%\n",
      "precision: 52.08%\n",
      "recall: 64.52%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "params_grid = {'criterion': ['gini', 'entropy'],\n",
    "               'max_depth': list(range(5, 10)),\n",
    "               'max_features': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "               'min_samples_leaf': list(range(3, 20))\n",
    "              }\n",
    "scorings = ['accuracy', \n",
    "            'f1', \n",
    "            'neg_log_loss', \n",
    "            'precision', \n",
    "            'r2', \n",
    "            'recall',\n",
    "            'roc_auc', \n",
    "            'v_measure_score']\n",
    "\n",
    "for i in scorings:\n",
    "    gs = GridSearchCV(clf, params_grid, scoring=i, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    clf = gs.best_estimator_\n",
    "    print('SCORING:', i)\n",
    "    print(clf)\n",
    "    print('accuracy: %.2f%%' % (100 * accuracy_score(clf.predict(X_test), y_test)))\n",
    "    print('precision: %.2f%%' % (100 * precision_score(clf.predict(X_test), y_test)))\n",
    "    print('recall: %.2f%%' % (100 * recall_score(clf.predict(X_test), y_test)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nОтвет:\\n\\nSCORING: precision\\naccuracy: 79.82%\\nprecision: 45.31%\\nrecall: 74.36%\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ответ:\n",
    "\n",
    "SCORING: precision\n",
    "accuracy: 79.82%\n",
    "precision: 45.31%\n",
    "recall: 74.36%\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оцените качество полученного алгоритма. (\\*) Оказалось ли оно лучше ранее изученных методов классификации для этой задачи? Если да, то почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1190 candidates, totalling 3570 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3570 out of 3570 | elapsed:   21.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=1.0, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=19, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "accuracy: 77.88%\n",
      "precision: 53.12%\n",
      "recall: 63.75%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=8000, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "accuracy: 71.15%\n",
      "precision: 0.52%\n",
      "recall: 33.33%\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "accuracy: 68.76%\n",
      "precision: 6.25%\n",
      "recall: 29.27%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "clfs = [DecisionTreeClassifier(), LogisticRegression(), LinearSVC()]\n",
    "\n",
    "params_grid = [\n",
    "                {\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                    'max_depth': list(range(5, 10)),\n",
    "                    'max_features': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "                    'min_samples_leaf': list(range(3, 20))\n",
    "                },\n",
    "                {\n",
    "                    'penalty': ['l2'], \n",
    "                    'C': [0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "                    'max_iter': list(range(1000, 10000, 1000))\n",
    "                },\n",
    "                {\n",
    "                    'penalty': ['l2'], \n",
    "                    'C': [0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "                    'max_iter': list(range(1000, 10000, 1000))\n",
    "                },\n",
    "]\n",
    "\n",
    "for i in range(len(clfs)):\n",
    "    gs = GridSearchCV(clfs[i], params_grid[i], scoring='roc_auc', verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    clfs[i] = gs.best_estimator_\n",
    "    print(clfs[i])\n",
    "    print('accuracy: %.2f%%' % (100 * accuracy_score(clfs[i].predict(X_test), y_test)))\n",
    "    print('precision: %.2f%%' % (100 * precision_score(clfs[i].predict(X_test), y_test)))\n",
    "    print('recall: %.2f%%' % (100 * recall_score(clfs[i].predict(X_test), y_test)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ответ*: Дерево отработало лучше на этом датасете. \n",
    "Так как линейные модели дают запредельно низкий precision. \n",
    "Очень много ложных позитивов: ложных отнесений к классу(очень часто относит к нерелевантному классу)\n",
    "Это понятно по recall-метрике: которая выше чем precision\n",
    "Возможно классы перемешаны и нет возможности провести четкую линию.\n",
    "Деревья же строят более точные разделяющие квадраты.\n",
    "Возможно для линейных моделей можно как-то трансформировать датасет для улучшения качества???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрите, как меняется качество на трейне и тесте по мере роста максимальной глубины дерева. Наблюдаете ли Вы переобучение? Что будет, если не ограничить дерево в своих размерах (max_depth=None)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH: None\n",
      "accuracy: 71.60%\n",
      "precision: 48.96%\n",
      "recall: 50.54%\n",
      "\n",
      "\n",
      "DEPTH: 1\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "DEPTH: 4\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "DEPTH: 5\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "DEPTH: 6\n",
      "accuracy: 78.03%\n",
      "precision: 48.96%\n",
      "recall: 65.73%\n",
      "\n",
      "\n",
      "DEPTH: 10\n",
      "accuracy: 74.14%\n",
      "precision: 42.19%\n",
      "recall: 56.64%\n",
      "\n",
      "\n",
      "DEPTH: 20\n",
      "accuracy: 72.20%\n",
      "precision: 51.56%\n",
      "recall: 51.56%\n",
      "\n",
      "\n",
      "DEPTH: 25\n",
      "accuracy: 72.05%\n",
      "precision: 48.96%\n",
      "recall: 51.37%\n",
      "\n",
      "\n",
      "DEPTH: 50\n",
      "accuracy: 72.05%\n",
      "precision: 50.00%\n",
      "recall: 51.34%\n",
      "\n",
      "\n",
      "DEPTH: 75\n",
      "accuracy: 72.50%\n",
      "precision: 51.04%\n",
      "recall: 52.13%\n",
      "\n",
      "\n",
      "DEPTH: 100\n",
      "accuracy: 73.69%\n",
      "precision: 51.04%\n",
      "recall: 54.44%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depth = [None, 1, 4, 5, 6, 10, 20, 25, 50, 75, 100]\n",
    "for i in depth:\n",
    "    clf = DecisionTreeClassifier(max_depth=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('DEPTH:', i)\n",
    "    print('accuracy: %.2f%%' % (100 * accuracy_score(clf.predict(X_test), y_test)))\n",
    "    print('precision: %.2f%%' % (100 * precision_score(clf.predict(X_test), y_test)))\n",
    "    print('recall: %.2f%%' % (100 * recall_score(clf.predict(X_test), y_test)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уменьшиться ли переобучение, если увеличить параметры min_samples_split и/или min_samples_leaf (см. Примечание 2)? (*) Какие ещё гиперпараметры могут помочь в борьбе с переобучением?¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMS None 2 1\n",
      "accuracy: 72.05%\n",
      "precision: 50.00%\n",
      "recall: 51.34%\n",
      "\n",
      "\n",
      "PARAMS None 2 2\n",
      "accuracy: 72.35%\n",
      "precision: 46.88%\n",
      "recall: 52.02%\n",
      "\n",
      "\n",
      "PARAMS None 2 3\n",
      "accuracy: 74.29%\n",
      "precision: 52.60%\n",
      "recall: 55.49%\n",
      "\n",
      "\n",
      "PARAMS None 2 4\n",
      "accuracy: 74.14%\n",
      "precision: 47.40%\n",
      "recall: 55.83%\n",
      "\n",
      "\n",
      "PARAMS None 3 1\n",
      "accuracy: 72.94%\n",
      "precision: 50.52%\n",
      "recall: 53.01%\n",
      "\n",
      "\n",
      "PARAMS None 3 2\n",
      "accuracy: 72.35%\n",
      "precision: 47.40%\n",
      "recall: 52.00%\n",
      "\n",
      "\n",
      "PARAMS None 3 3\n",
      "accuracy: 72.94%\n",
      "precision: 52.08%\n",
      "recall: 52.91%\n",
      "\n",
      "\n",
      "PARAMS None 3 4\n",
      "accuracy: 74.74%\n",
      "precision: 48.44%\n",
      "recall: 57.06%\n",
      "\n",
      "\n",
      "PARAMS None 4 1\n",
      "accuracy: 72.94%\n",
      "precision: 50.52%\n",
      "recall: 53.01%\n",
      "\n",
      "\n",
      "PARAMS None 4 2\n",
      "accuracy: 73.09%\n",
      "precision: 48.96%\n",
      "recall: 53.41%\n",
      "\n",
      "\n",
      "PARAMS None 4 3\n",
      "accuracy: 74.29%\n",
      "precision: 54.69%\n",
      "recall: 55.26%\n",
      "\n",
      "\n",
      "PARAMS None 4 4\n",
      "accuracy: 75.19%\n",
      "precision: 51.04%\n",
      "recall: 57.65%\n",
      "\n",
      "\n",
      "PARAMS 1 2 1\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 2 2\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 2 3\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 2 4\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 3 1\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 3 2\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 3 3\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 3 4\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 4 1\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 4 2\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 4 3\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 1 4 4\n",
      "accuracy: 72.65%\n",
      "precision: 34.90%\n",
      "recall: 53.60%\n",
      "\n",
      "\n",
      "PARAMS 4 2 1\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 2 2\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 2 3\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 2 4\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 3 1\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 3 2\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 3 3\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 3 4\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 4 1\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 4 2\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 4 3\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 4 4 4\n",
      "accuracy: 77.28%\n",
      "precision: 44.79%\n",
      "recall: 65.15%\n",
      "\n",
      "\n",
      "PARAMS 5 2 1\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 2 2\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 2 3\n",
      "accuracy: 78.33%\n",
      "precision: 40.62%\n",
      "recall: 71.56%\n",
      "\n",
      "\n",
      "PARAMS 5 2 4\n",
      "accuracy: 78.18%\n",
      "precision: 41.15%\n",
      "recall: 70.54%\n",
      "\n",
      "\n",
      "PARAMS 5 3 1\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 3 2\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 3 3\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 3 4\n",
      "accuracy: 78.18%\n",
      "precision: 41.15%\n",
      "recall: 70.54%\n",
      "\n",
      "\n",
      "PARAMS 5 4 1\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 4 2\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 4 3\n",
      "accuracy: 78.18%\n",
      "precision: 40.62%\n",
      "recall: 70.91%\n",
      "\n",
      "\n",
      "PARAMS 5 4 4\n",
      "accuracy: 78.48%\n",
      "precision: 41.15%\n",
      "recall: 71.82%\n",
      "\n",
      "\n",
      "PARAMS 6 2 1\n",
      "accuracy: 78.18%\n",
      "precision: 48.96%\n",
      "recall: 66.20%\n",
      "\n",
      "\n",
      "PARAMS 6 2 2\n",
      "accuracy: 78.18%\n",
      "precision: 48.96%\n",
      "recall: 66.20%\n",
      "\n",
      "\n",
      "PARAMS 6 2 3\n",
      "accuracy: 77.58%\n",
      "precision: 48.96%\n",
      "recall: 64.38%\n",
      "\n",
      "\n",
      "PARAMS 6 2 4\n",
      "accuracy: 77.43%\n",
      "precision: 46.35%\n",
      "recall: 64.96%\n",
      "\n",
      "\n",
      "PARAMS 6 3 1\n",
      "accuracy: 78.18%\n",
      "precision: 48.96%\n",
      "recall: 66.20%\n",
      "\n",
      "\n",
      "PARAMS 6 3 2\n",
      "accuracy: 78.18%\n",
      "precision: 48.96%\n",
      "recall: 66.20%\n",
      "\n",
      "\n",
      "PARAMS 6 3 3\n",
      "accuracy: 77.58%\n",
      "precision: 48.96%\n",
      "recall: 64.38%\n",
      "\n",
      "\n",
      "PARAMS 6 3 4\n",
      "accuracy: 77.43%\n",
      "precision: 46.35%\n",
      "recall: 64.96%\n",
      "\n",
      "\n",
      "PARAMS 6 4 1\n",
      "accuracy: 77.88%\n",
      "precision: 48.96%\n",
      "recall: 65.28%\n",
      "\n",
      "\n",
      "PARAMS 6 4 2\n",
      "accuracy: 78.18%\n",
      "precision: 48.96%\n",
      "recall: 66.20%\n",
      "\n",
      "\n",
      "PARAMS 6 4 3\n",
      "accuracy: 77.88%\n",
      "precision: 48.96%\n",
      "recall: 65.28%\n",
      "\n",
      "\n",
      "PARAMS 6 4 4\n",
      "accuracy: 77.73%\n",
      "precision: 46.35%\n",
      "recall: 65.93%\n",
      "\n",
      "\n",
      "PARAMS 10 2 1\n",
      "accuracy: 74.29%\n",
      "precision: 44.79%\n",
      "recall: 56.58%\n",
      "\n",
      "\n",
      "PARAMS 10 2 2\n",
      "accuracy: 75.04%\n",
      "precision: 49.48%\n",
      "recall: 57.58%\n",
      "\n",
      "\n",
      "PARAMS 10 2 3\n",
      "accuracy: 75.04%\n",
      "precision: 51.04%\n",
      "recall: 57.31%\n",
      "\n",
      "\n",
      "PARAMS 10 2 4\n",
      "accuracy: 74.59%\n",
      "precision: 44.79%\n",
      "recall: 57.33%\n",
      "\n",
      "\n",
      "PARAMS 10 3 1\n",
      "accuracy: 74.89%\n",
      "precision: 46.35%\n",
      "recall: 57.79%\n",
      "\n",
      "\n",
      "PARAMS 10 3 2\n",
      "accuracy: 74.44%\n",
      "precision: 46.35%\n",
      "recall: 56.69%\n",
      "\n",
      "\n",
      "PARAMS 10 3 3\n",
      "accuracy: 74.74%\n",
      "precision: 50.52%\n",
      "recall: 56.73%\n",
      "\n",
      "\n",
      "PARAMS 10 3 4\n",
      "accuracy: 74.29%\n",
      "precision: 45.31%\n",
      "recall: 56.49%\n",
      "\n",
      "\n",
      "PARAMS 10 4 1\n",
      "accuracy: 74.29%\n",
      "precision: 45.83%\n",
      "recall: 56.41%\n",
      "\n",
      "\n",
      "PARAMS 10 4 2\n",
      "accuracy: 74.74%\n",
      "precision: 46.35%\n",
      "recall: 57.42%\n",
      "\n",
      "\n",
      "PARAMS 10 4 3\n",
      "accuracy: 73.54%\n",
      "precision: 48.96%\n",
      "recall: 54.34%\n",
      "\n",
      "\n",
      "PARAMS 10 4 4\n",
      "accuracy: 75.19%\n",
      "precision: 46.88%\n",
      "recall: 58.44%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depth = [None, 1, 4, 5, 6, 10]\n",
    "min_samples_splits = list(range(2, 5))\n",
    "min_samples_leafs = list(range(1, 5))\n",
    "\n",
    "for i in depth:\n",
    "    for s in min_samples_splits:\n",
    "        for l in min_samples_leafs:\n",
    "            clf = DecisionTreeClassifier(max_depth=i, min_samples_split=s, min_samples_leaf=l)\n",
    "            clf.fit(X_train, y_train)\n",
    "            print('PARAMS', i, s, l)\n",
    "            print('accuracy: %.2f%%' % (100 * accuracy_score(clf.predict(X_test), y_test)))\n",
    "            print('precision: %.2f%%' % (100 * precision_score(clf.predict(X_test), y_test)))\n",
    "            print('recall: %.2f%%' % (100 * recall_score(clf.predict(X_test), y_test)))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
