{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBcKvo5l7GSj"
   },
   "source": [
    "## Линейные методы. Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi_m3iyo7GSn"
   },
   "source": [
    "Vowpal Wabbit on GitHub: https://github.com/JohnLangford/vowpal_wabbit\n",
    "\n",
    "Vowpal Wabbit Tutorial: https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "lNecNKWS7INt",
    "outputId": "3b06b940-e9bc-41ea-ae35-b40daabd339f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install vowpal-wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "HB2bBWSY7dqQ",
    "outputId": "6d0de8d6-1acf-49e4-d053-1fa2027798ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-24 16:29:31--  https://www.dropbox.com/s/crld672bipr0n05/train-sample.csv?dl=0\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.1\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/crld672bipr0n05/train-sample.csv [переход]\n",
      "--2019-01-24 16:29:33--  https://www.dropbox.com/s/raw/crld672bipr0n05/train-sample.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com/cd/0/inline/AaAkA_WeejtYNGru7o-LMRhq7vmQULwtO_s9MEG4UcgqrN24DUnmlYQeFh56VLd7y_rWGnpovBOOXP3E1-y6QqkuXpzq7HkPIVEJjYA-snjxnA/file# [переход]\n",
      "--2019-01-24 16:29:34--  https://ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com/cd/0/inline/AaAkA_WeejtYNGru7o-LMRhq7vmQULwtO_s9MEG4UcgqrN24DUnmlYQeFh56VLd7y_rWGnpovBOOXP3E1-y6QqkuXpzq7HkPIVEJjYA-snjxnA/file\n",
      "Распознаётся ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com (ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com)… 162.125.70.6\n",
      "Подключение к ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com (ucd4002c0739e14a53c8ba45d8e4.dl.dropboxusercontent.com)|162.125.70.6|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 139669798 (133M) [text/plain]\n",
      "Сохранение в: «train-sample.csv?dl=0»\n",
      "\n",
      "train-sample.csv?dl 100%[===================>] 133,20M  1,48MB/s    за 97s     \n",
      "\n",
      "2019-01-24 16:31:13 (1,38 MB/s) - «train-sample.csv?dl=0» сохранён [139669798/139669798]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/crld672bipr0n05/train-sample.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fwZicsmo7x5R",
    "outputId": "33f4d87b-1b30-4779-e1f4-295d739c690e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBlending.pdf\u001b[m\u001b[m              \u001b[31mtest_medium.csv\u001b[m\u001b[m           \u001b[31mvw_tutorial.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mBlendingStacking.ipynb\u001b[m\u001b[m    train-sample.csv?dl=0     \u001b[31mvw_tutorial.pdf\u001b[m\u001b[m\r\n",
      "\u001b[31mGD.pdf\u001b[m\u001b[m                    train-sample.csv?dl=0.zip \u001b[31mvw_vs_xgb.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mREADME.md\u001b[m\u001b[m                 \u001b[31mtrain_medium.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-aEqmcM7GSp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tqiyrtOL7GSu"
   },
   "outputs": [],
   "source": [
    "train_path = 'train-sample.csv?dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oyK42i_h7GSy",
    "outputId": "b7d043ae-2784-4054-fb42-2815d092d511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(train_path)\n",
    "data.head()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6046168</td>\n",
       "      <td>05/18/2011 14:14:05</td>\n",
       "      <td>543315</td>\n",
       "      <td>09/17/2010 10:15:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>I am building a corpus of indexed sentences in...</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4873911</td>\n",
       "      <td>02/02/2011 11:30:10</td>\n",
       "      <td>465076</td>\n",
       "      <td>10/03/2010 09:30:58</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>i create a xml document with JAXP and search a...</td>\n",
       "      <td>dom</td>\n",
       "      <td>xsd</td>\n",
       "      <td>jaxp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3311559</td>\n",
       "      <td>07/22/2010 17:21:54</td>\n",
       "      <td>406143</td>\n",
       "      <td>07/22/2010 16:58:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Too many lookup tables</td>\n",
       "      <td>What are the adverse effects of having too man...</td>\n",
       "      <td>sql-server</td>\n",
       "      <td>database-design</td>\n",
       "      <td>enums</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9990413</td>\n",
       "      <td>04/03/2012 09:18:39</td>\n",
       "      <td>851755</td>\n",
       "      <td>07/19/2011 10:22:40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>What is this PHP code in VB.net</td>\n",
       "      <td>I am looking for the vb.net equivalent of this...</td>\n",
       "      <td>php</td>\n",
       "      <td>vb.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/15/2012 21:12:48</td>\n",
       "      <td>too localized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10421966</td>\n",
       "      <td>05/02/2012 21:25:01</td>\n",
       "      <td>603588</td>\n",
       "      <td>02/04/2011 18:05:34</td>\n",
       "      <td>334</td>\n",
       "      <td>14</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>With Spring-Data, you can use the @Document an...</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>spring-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId     PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n",
       "0   6046168  05/18/2011 14:14:05       543315  09/17/2010 10:15:06   \n",
       "1   4873911  02/02/2011 11:30:10       465076  10/03/2010 09:30:58   \n",
       "2   3311559  07/22/2010 17:21:54       406143  07/22/2010 16:58:20   \n",
       "3   9990413  04/03/2012 09:18:39       851755  07/19/2011 10:22:40   \n",
       "4  10421966  05/02/2012 21:25:01       603588  02/04/2011 18:05:34   \n",
       "\n",
       "   ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "0                         1                                    2   \n",
       "1                       192                                   24   \n",
       "2                         1                                    0   \n",
       "3                         4                                    1   \n",
       "4                       334                                   14   \n",
       "\n",
       "                                               Title  \\\n",
       "0  For Mongodb is it better to reference an objec...   \n",
       "1  How to insert schemalocation in a xml document...   \n",
       "2                            Too many lookup tables    \n",
       "3                    What is this PHP code in VB.net   \n",
       "4  Spring-Data mongodb querying multiple classes ...   \n",
       "\n",
       "                                        BodyMarkdown        Tag1  \\\n",
       "0  I am building a corpus of indexed sentences in...     mongodb   \n",
       "1  i create a xml document with JAXP and search a...         dom   \n",
       "2  What are the adverse effects of having too man...  sql-server   \n",
       "3  I am looking for the vb.net equivalent of this...         php   \n",
       "4  With Spring-Data, you can use the @Document an...     mongodb   \n",
       "\n",
       "              Tag2   Tag3 Tag4 Tag5       PostClosedDate     OpenStatus  \n",
       "0              NaN    NaN  NaN  NaN                  NaN           open  \n",
       "1              xsd   jaxp  NaN  NaN                  NaN           open  \n",
       "2  database-design  enums  NaN  NaN                  NaN           open  \n",
       "3           vb.net    NaN  NaN  NaN  04/15/2012 21:12:48  too localized  \n",
       "4      spring-data    NaN  NaN  NaN                  NaN           open  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hIe6dY5y7GS4",
    "outputId": "d95f6f13-c8d8-4456-9cdc-1f6224f4366b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open\n",
      "i have two dimensions, first (width, height) and second(width1, height1). how can i retrieve a Point(x,y) from dimensions???\n"
     ]
    }
   ],
   "source": [
    "print(data.OpenStatus[10])\n",
    "print(data.BodyMarkdown[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Mnd3r_V47GS9"
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[:50000, :]\n",
    "data_test = data.iloc[70000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tR2l6tkW7GTA"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def save_to_vw(data, fname):\n",
    "    with open(fname, 'w') as fout:\n",
    "        for _, row in data.iterrows():\n",
    "            text = filter(lambda x: len(x) > 1, re.split(\"[^a-z]\",\n",
    "                                    row.BodyMarkdown.lower()))\n",
    "            text = ' '.join(text)\n",
    "            if row.OpenStatus == \"open\":\n",
    "                target = 1\n",
    "            else:\n",
    "                target = -1\n",
    "            fout.write('{0} |n 0:{1} {2} |t {3}\\n'.format(target, \n",
    "                                        row.ReputationAtPostCreation,\n",
    "                                        row.Tag1,\n",
    "                                        text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UBlbJx3C7GTD"
   },
   "outputs": [],
   "source": [
    "save_to_vw(data_train, 'train.vw')\n",
    "save_to_vw(data_test, 'test.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Yse2dRCV8-DX",
    "outputId": "303f9ede-3e1c-4a30-8c7d-86a4ffc2f970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBlending.pdf\u001b[m\u001b[m           test.vw                \u001b[31mvw_tutorial.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mBlendingStacking.ipynb\u001b[m\u001b[m \u001b[31mtest_medium.csv\u001b[m\u001b[m        \u001b[31mvw_tutorial.pdf\u001b[m\u001b[m\r\n",
      "\u001b[31mGD.pdf\u001b[m\u001b[m                 train-sample.csv?dl=0  \u001b[31mvw_vs_xgb.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mREADME.md\u001b[m\u001b[m              train.vw\r\n",
      "\u001b[1m\u001b[36mtargetdir\u001b[m\u001b[m              \u001b[31mtrain_medium.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "tOjgsuDY7GTG",
    "outputId": "929de2d4-3ca8-459b-f6d9-615807f1eab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |n 0:1 mongodb |t am building corpus of indexed sentences in different languages have collection of languages which have both an objectid and the iso code as key is it better to use reference to the language collection or store key like en or fr suppose it compromise between ease of referencing the language object in that collection speed in doing queries where the sentence has certain language the size of the data on disk any best practices that should know of\r\n",
      "1 |n 0:192 dom |t create xml document with jaxp and search way to insert the schemalocation at the moment my application produces xml version encoding utf root root but need xml version encoding utf root xmlns namespaceurl xmlns xs http www org xmlschema instance xs schemalocation namespaceurl pathtomyschema xsd root my code streamresult result new streamresult writer document doc getdocument transformer trans transfac newtransformer trans setoutputproperty outputkeys indent yes trans setoutputproperty outputkeys method xml trans setoutputproperty outputkeys version trans setoutputproperty outputkeys encoding utf domsource source new domsource depl getaselement doc trans transform source result thanks for your time kasten\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "colab_type": "code",
    "id": "TFe67Th17GTM",
    "outputId": "151efe1e-4efc-4283-db65-fe7e41504f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000       81\n",
      "0.500000 0.000000            2            2.0   1.0000   0.7311       98\n",
      "0.906326 1.312652            4            4.0  -1.0000   0.6051      110\n",
      "0.821724 0.737121            8            8.0  -1.0000   0.6143       38\n",
      "0.875065 0.928406           16           16.0   1.0000   0.6741      136\n",
      "0.906826 0.938586           32           32.0   1.0000   0.6249       93\n",
      "0.996030 1.085234           64           64.0   1.0000   0.6714       71\n",
      "0.977266 0.958502          128          128.0  -1.0000   0.4202       24\n",
      "0.990424 1.003582          256          256.0  -1.0000   0.5678       61\n",
      "0.969661 0.948898          512          512.0   1.0000   0.4182       33\n",
      "0.939473 0.909285         1024         1024.0   1.0000   0.4303      189\n",
      "0.933614 0.927755         2048         2048.0  -1.0000   0.3808       24\n",
      "0.915891 0.898168         4096         4096.0  -1.0000   0.6471       38\n",
      "0.900047 0.884203         8192         8192.0  -1.0000   0.4138       16\n",
      "0.849803 0.799560        16384        16384.0   1.0000   0.7311      296\n",
      "0.822175 0.794546        32768        32768.0  -1.0000   0.2689      101\n",
      "0.809637 0.809637        65536        65536.0   1.0000   0.7311      176 h\n",
      "0.808070 0.806503       131072       131072.0  -1.0000   0.3770       10 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 5\n",
      "weighted example sum = 225000.000000\n",
      "weighted label sum = 180.000000\n",
      "average loss = 0.799743 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 24653095\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 --link logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "u-hgdhJH7GTQ",
    "outputId": "4d5f0e6b-2a20-4f89-ff95-8ab2492189df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      187\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      126\n",
      "1.000000 2.000000            4            4.0  -1.0000   0.7311      516\n",
      "0.650952 0.301905            8            8.0   1.0000   0.6917      117\n",
      "0.710308 0.769664           16           16.0   1.0000   0.5795      155\n",
      "0.613737 0.517167           32           32.0   1.0000   0.4811       48\n",
      "0.827671 1.041604           64           64.0  -1.0000   0.7311      226\n",
      "0.809134 0.790597          128          128.0   1.0000   0.5220       86\n",
      "0.811060 0.812986          256          256.0  -1.0000   0.5069       83\n",
      "0.832522 0.853984          512          512.0   1.0000   0.6616      103\n",
      "0.845617 0.858713         1024         1024.0  -1.0000   0.3577       24\n",
      "0.821638 0.797658         2048         2048.0  -1.0000   0.2689      156\n",
      "0.803879 0.786120         4096         4096.0   1.0000   0.7311      167\n",
      "0.812926 0.821972         8192         8192.0  -1.0000   0.4674       45\n",
      "0.809648 0.806370        16384        16384.0  -1.0000   0.4374       81\n",
      "0.808320 0.806992        32768        32768.0  -1.0000   0.6075       66\n",
      "0.805946 0.803573        65536        65536.0   1.0000   0.7311       72\n",
      "\n",
      "finished run\n",
      "number of examples = 70272\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.806739\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 7697580\n"
     ]
    }
   ],
   "source": [
    "!vw -d test.vw -i model.vw -t -p pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "_SUo1dLe7GTT",
    "outputId": "de4fc9e7-6125-4aca-ffad-0ae6f951f94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731059\r\n",
      "0.731059\r\n",
      "0.268941\r\n",
      "0.731059\r\n",
      "0.520487\r\n",
      "0.731059\r\n",
      "0.268941\r\n",
      "0.691658\r\n",
      "0.462321\r\n",
      "0.344322\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6FaIQr2w7GTX",
    "outputId": "1ae2f4af-b8fe-4b2c-8a81-c817e1d91a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749397478828419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_vw_qual():\n",
    "    preds = pd.read_csv('pred.txt', header=None).iloc[:, 0].values\n",
    "    target = data_test.OpenStatus.values\n",
    "    T = []\n",
    "    for t in target:\n",
    "        if t == 'open':\n",
    "            T.append(1.)\n",
    "        else:\n",
    "            T.append(-1.)\n",
    "    print(roc_auc_score(T, preds))\n",
    "    \n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1456
    },
    "colab_type": "code",
    "id": "ZRdEFZFp7GTb",
    "outputId": "c4d420c3-341f-4371-f1c4-96d5b342093a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000       81\n",
      "0.500000 0.000000            2            2.0   1.0000   0.7311       98\n",
      "0.812846 1.125692            4            4.0  -1.0000   0.5555      110\n",
      "0.769143 0.725440            8            8.0  -1.0000   0.5734       38\n",
      "0.845550 0.921957           16           16.0   1.0000   0.6202      136\n",
      "0.812974 0.780397           32           32.0   1.0000   0.6439       93\n",
      "0.899824 0.986675           64           64.0   1.0000   0.5865       71\n",
      "0.894960 0.890097          128          128.0  -1.0000   0.4753       24\n",
      "0.893272 0.891584          256          256.0  -1.0000   0.5065       61\n",
      "0.917625 0.941978          512          512.0   1.0000   0.4394       33\n",
      "0.897855 0.878085         1024         1024.0   1.0000   0.4614      189\n",
      "0.879552 0.861248         2048         2048.0  -1.0000   0.4293       24\n",
      "0.856456 0.833361         4096         4096.0  -1.0000   0.5592       38\n",
      "0.839280 0.822103         8192         8192.0  -1.0000   0.4623       16\n",
      "0.806363 0.773447        16384        16384.0   1.0000   0.7311      296\n",
      "0.783823 0.761283        32768        32768.0  -1.0000   0.2689      101\n",
      "0.767486 0.767486        65536        65536.0   1.0000   0.7311      176 h\n",
      "0.759694 0.751904       131072       131072.0  -1.0000   0.4160       10 h\n",
      "0.751582 0.743470       262144       262144.0   1.0000   0.7311      352 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.744281 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 34514333\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      187\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      126\n",
      "1.000614 2.001227            4            4.0  -1.0000   0.7311      516\n",
      "0.650460 0.300306            8            8.0   1.0000   0.7311      117\n",
      "0.649729 0.648999           16           16.0   1.0000   0.5482      155\n",
      "0.556576 0.463422           32           32.0   1.0000   0.5081       48\n",
      "0.704163 0.851750           64           64.0  -1.0000   0.5408      226\n",
      "0.692772 0.681382          128          128.0   1.0000   0.5609       86\n",
      "0.717331 0.741889          256          256.0  -1.0000   0.4951       83\n",
      "0.756175 0.795020          512          512.0   1.0000   0.7062      103\n",
      "0.765709 0.775242         1024         1024.0  -1.0000   0.3921       24\n",
      "0.748074 0.730438         2048         2048.0  -1.0000   0.2962      156\n",
      "0.745719 0.743364         4096         4096.0   1.0000   0.7311      167\n",
      "0.751567 0.757415         8192         8192.0  -1.0000   0.4614       45\n",
      "0.750411 0.749254        16384        16384.0  -1.0000   0.4464       81\n",
      "0.750509 0.750607        32768        32768.0  -1.0000   0.5913       66\n",
      "0.749125 0.747742        65536        65536.0   1.0000   0.7311       72\n",
      "\n",
      "finished run\n",
      "number of examples = 70272\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.749840\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 7697580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7984633419689834\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Ina55A67GTe"
   },
   "source": [
    "n-граммы (n=2) - индикаторы того, что два слова встретились рядом. Из \"мама мыла раму\" получаем биграммы \"мама мыла\" и \"мыла раму\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1491
    },
    "colab_type": "code",
    "id": "Vg6sQOnh7GTg",
    "outputId": "2af38293-37a6-4518-9d04-77d850b751f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      158\n",
      "0.501991 0.003982            2            2.0   1.0000   0.7185      192\n",
      "0.769028 1.036065            4            4.0  -1.0000   0.5258      216\n",
      "0.788365 0.807701            8            8.0  -1.0000   0.5554       72\n",
      "0.853561 0.918757           16           16.0   1.0000   0.5926      268\n",
      "0.815435 0.777309           32           32.0   1.0000   0.6290      182\n",
      "0.899736 0.984037           64           64.0   1.0000   0.5476      138\n",
      "0.899076 0.898416          128          128.0  -1.0000   0.4850       44\n",
      "0.900915 0.902754          256          256.0  -1.0000   0.5106      118\n",
      "0.919717 0.938519          512          512.0   1.0000   0.4590       62\n",
      "0.894198 0.868679         1024         1024.0   1.0000   0.4761      374\n",
      "0.874036 0.853875         2048         2048.0  -1.0000   0.4419       44\n",
      "0.848005 0.821974         4096         4096.0  -1.0000   0.5279       72\n",
      "0.832330 0.816654         8192         8192.0  -1.0000   0.4895       28\n",
      "0.799748 0.767167        16384        16384.0   1.0000   0.7311      588\n",
      "0.771801 0.743855        32768        32768.0  -1.0000   0.2689      198\n",
      "0.758017 0.758017        65536        65536.0   1.0000   0.7311      348 h\n",
      "0.748930 0.739845       131072       131072.0  -1.0000   0.4163       16 h\n",
      "0.742015 0.735099       262144       262144.0   1.0000   0.7311      700 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.735132 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 67768757\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      370\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      248\n",
      "1.000416 2.000831            4            4.0  -1.0000   0.7311     1028\n",
      "0.726775 0.453134            8            8.0   1.0000   0.7311      230\n",
      "0.611760 0.496745           16           16.0   1.0000   0.7288      306\n",
      "0.530342 0.448924           32           32.0   1.0000   0.5067       92\n",
      "0.677202 0.824062           64           64.0  -1.0000   0.4670      448\n",
      "0.679827 0.682453          128          128.0   1.0000   0.5748      168\n",
      "0.680356 0.680885          256          256.0  -1.0000   0.5740      162\n",
      "0.712045 0.743733          512          512.0   1.0000   0.7311      202\n",
      "0.728470 0.744896         1024         1024.0  -1.0000   0.3969       44\n",
      "0.714591 0.700711         2048         2048.0  -1.0000   0.3404      308\n",
      "0.720521 0.726451         4096         4096.0   1.0000   0.7199      330\n",
      "0.728133 0.735746         8192         8192.0  -1.0000   0.4562       86\n",
      "0.733180 0.738227        16384        16384.0  -1.0000   0.4794      158\n",
      "0.736419 0.739658        32768        32768.0  -1.0000   0.5624      128\n",
      "0.735185 0.733952        65536        65536.0   1.0000   0.7311      140\n",
      "\n",
      "finished run\n",
      "number of examples = 70272\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.736169\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 15114088\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8049261852114356\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWsWp25t7GTj"
   },
   "source": [
    "k-skip-n-граммы - как n-граммы, но разрешаем словам быть отдаленными друг от друга не больше, чем на k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1525
    },
    "colab_type": "code",
    "id": "D3EXDeI67GTm",
    "outputId": "e0d77434-cff6-48ec-f8f5-8cb18e11df8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      309\n",
      "0.598903 0.197807            2            2.0   1.0000   0.6354      377\n",
      "0.813193 1.027482            4            4.0  -1.0000   0.5188      425\n",
      "0.827788 0.842383            8            8.0  -1.0000   0.5387      137\n",
      "0.878166 0.928544           16           16.0   1.0000   0.5696      529\n",
      "0.833454 0.788743           32           32.0   1.0000   0.6141      357\n",
      "0.919097 1.004739           64           64.0   1.0000   0.5475      269\n",
      "0.925038 0.930980          128          128.0  -1.0000   0.4903       81\n",
      "0.922979 0.920921          256          256.0  -1.0000   0.4998      229\n",
      "0.931385 0.939790          512          512.0   1.0000   0.4615      117\n",
      "0.903010 0.874635         1024         1024.0   1.0000   0.4652      741\n",
      "0.888596 0.874181         2048         2048.0  -1.0000   0.4493       81\n",
      "0.858703 0.828809         4096         4096.0  -1.0000   0.5026      137\n",
      "0.841166 0.823629         8192         8192.0  -1.0000   0.4816       49\n",
      "0.809038 0.776910        16384        16384.0   1.0000   0.7311     1169\n",
      "0.778904 0.748770        32768        32768.0  -1.0000   0.2689      389\n",
      "0.765945 0.765945        65536        65536.0   1.0000   0.7311      689 h\n",
      "0.755040 0.744135       131072       131072.0  -1.0000   0.4247       25 h\n",
      "0.747567 0.740094       262144       262144.0   1.0000   0.7311     1393 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000.000000\n",
      "weighted label sum = 216.000000\n",
      "average loss = 0.739266 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 114285174\n",
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      733\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      489\n",
      "1.000491 2.000982            4            4.0  -1.0000   0.7311     2049\n",
      "0.657112 0.313733            8            8.0   1.0000   0.7311      453\n",
      "0.500794 0.344475           16           16.0   1.0000   0.7164      605\n",
      "0.506039 0.511283           32           32.0   1.0000   0.4979      177\n",
      "0.681006 0.855974           64           64.0  -1.0000   0.6381      889\n",
      "0.664312 0.647617          128          128.0   1.0000   0.5470      329\n",
      "0.681360 0.698408          256          256.0  -1.0000   0.5694      317\n",
      "0.714270 0.747180          512          512.0   1.0000   0.7311      397\n",
      "0.724620 0.734969         1024         1024.0  -1.0000   0.4088       81\n",
      "0.719654 0.714688         2048         2048.0  -1.0000   0.3190      609\n",
      "0.725633 0.731613         4096         4096.0   1.0000   0.6793      653\n",
      "0.732191 0.738748         8192         8192.0  -1.0000   0.4654      165\n",
      "0.736436 0.740680        16384        16384.0  -1.0000   0.4838      309\n",
      "0.740426 0.744416        32768        32768.0  -1.0000   0.5634      249\n",
      "0.740818 0.741211        65536        65536.0   1.0000   0.7311      273\n",
      "\n",
      "finished run\n",
      "number of examples = 70272\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.741549\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 29736304\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8020425595639054\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 --skips t2 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1545
    },
    "colab_type": "code",
    "id": "YQNfl4T67GTq",
    "outputId": "1b9cd04a-9dc6-41d3-fa7b-43a87d4d1975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.5000      158\n",
      "0.501991 0.003982            2            2.0   1.0000   0.7185      192\n",
      "0.768823 1.035654            4            4.0  -1.0000   0.5257      216\n",
      "0.788250 0.807676            8            8.0  -1.0000   0.5554       72\n",
      "0.852059 0.915868           16           16.0   1.0000   0.5925      268\n",
      "0.814879 0.777699           32           32.0   1.0000   0.6291      182\n",
      "0.897638 0.980397           64           64.0   1.0000   0.5502      138\n",
      "0.897445 0.897252          128          128.0  -1.0000   0.4850       44\n",
      "0.898531 0.899617          256          256.0  -1.0000   0.5115      118\n",
      "0.919904 0.941277          512          512.0   1.0000   0.4604       62\n",
      "0.893383 0.866862         1024         1024.0   1.0000   0.4641      374\n",
      "0.874990 0.856597         2048         2048.0  -1.0000   0.4413       44\n",
      "0.846852 0.818714         4096         4096.0  -1.0000   0.5371       72\n",
      "0.830443 0.814034         8192         8192.0  -1.0000   0.4929       28\n",
      "0.796314 0.762186        16384        16384.0   1.0000   0.7311      588\n",
      "0.767529 0.738743        32768        32768.0  -1.0000   0.2689      198\n",
      "0.752728 0.752728        65536        65536.0   1.0000   0.7311      348 h\n",
      "0.742912 0.733097       131072       131072.0  -1.0000   0.4265       16 h\n",
      "0.733790 0.724669       262144       262144.0   1.0000   0.7311      700 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 7\n",
      "weighted example sum = 315000.000000\n",
      "weighted label sum = 252.000000\n",
      "average loss = 0.725734 h\n",
      "best constant = 0.000800\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 67768757\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0   1.0000   0.7311      370\n",
      "0.000000 0.000000            2            2.0   1.0000   0.7311      248\n",
      "1.010778 2.021555            4            4.0  -1.0000   0.7311     1028\n",
      "0.660963 0.311149            8            8.0   1.0000   0.7311      230\n",
      "0.535012 0.409061           16           16.0   1.0000   0.6425      306\n",
      "0.523252 0.511491           32           32.0   1.0000   0.4812       92\n",
      "0.690913 0.858574           64           64.0  -1.0000   0.5924      448\n",
      "0.662273 0.633633          128          128.0   1.0000   0.5510      168\n",
      "0.702459 0.742646          256          256.0  -1.0000   0.5019      162\n",
      "0.721151 0.739842          512          512.0   1.0000   0.7311      202\n",
      "0.731540 0.741929         1024         1024.0  -1.0000   0.4013       44\n",
      "0.713196 0.694852         2048         2048.0  -1.0000   0.3860      308\n",
      "0.723218 0.733240         4096         4096.0   1.0000   0.7182      330\n",
      "0.723556 0.723894         8192         8192.0  -1.0000   0.4688       86\n",
      "0.724842 0.726127        16384        16384.0  -1.0000   0.4644      158\n",
      "0.727341 0.729841        32768        32768.0  -1.0000   0.5632      128\n",
      "0.727127 0.726912        65536        65536.0   1.0000   0.7311      140\n",
      "\n",
      "finished run\n",
      "number of examples = 70272\n",
      "weighted example sum = 70272.000000\n",
      "weighted label sum = -94.000000\n",
      "average loss = 0.727744\n",
      "best constant = -0.001338\n",
      "best constant's loss = 0.999998\n",
      "total feature number = 15114088\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.811472836034993\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 -b 28 --link logistic\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print('\\n\\n\\n')\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rlJz_9ly7GTu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "vw_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
