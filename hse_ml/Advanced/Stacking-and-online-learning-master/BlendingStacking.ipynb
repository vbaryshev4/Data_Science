{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting, Stacking and Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X_full = data.data\n",
    "y_full = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, \n",
    "                                        random_state=241)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.35, \n",
    "                                        random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(Xtrain.shape[0], shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.156913688212926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "print(cross_val_score(rf, Xtrain, ytrain, cv=cv, scoring ='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.955697902097905"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf.fit(Xtrain, ytrain)\n",
    "pred_rf = rf.predict(Xval)\n",
    "mean_squared_error(pred_rf, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17.380011927514122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor()\n",
    "print(cross_val_score(ada, Xtrain, ytrain, cv=cv, scoring ='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.011518542332666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(Xtrain, ytrain)\n",
    "pred_ada = ada.predict(Xval)\n",
    "mean_squared_error(pred_ada, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) смешаем алгоритмы с весами 1:1, то есть в качестве ответа предскажем среднее значение смеси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction: 10.241624814300708\n",
      "Test prediction: 9.670834022421047\n"
     ]
    }
   ],
   "source": [
    "pred_mix_1 = 0.5 *(pred_rf + pred_ada)\n",
    "print('Validation prediction:',mean_squared_error(pred_mix_1, yval))\n",
    "\n",
    "rf_test = rf.predict(X_test)\n",
    "ada_test = ada.predict(X_test)\n",
    "pred_test_1 = 0.5 *(rf_test + ada_test)\n",
    "print('Test prediction:',mean_squared_error(pred_test_1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Смешаем алгоритмы с весами $\\alpha$ : $1-\\alpha$. Подберём $\\alpha$ в цикле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 10.090030224977806\n"
     ]
    }
   ],
   "source": [
    "max_score = -100\n",
    "opt_alpha = 0\n",
    "\n",
    "for alpha in np.arange(0.01,1.01,0.01):\n",
    "    pred_mix_2 = alpha * pred_rf + (1-alpha) * pred_ada\n",
    "    curr_score = -mean_squared_error(pred_mix_2, yval)\n",
    "    \n",
    "    if curr_score > max_score:\n",
    "        max_score = curr_score\n",
    "        opt_alpha = alpha\n",
    "        \n",
    "print(opt_alpha, -max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction: 10.060504460467717\n"
     ]
    }
   ],
   "source": [
    "rf_test = rf.predict(X_test)\n",
    "ada_test = ada.predict(X_test)\n",
    "pred_test_2 = opt_alpha * rf_test + (1-opt_alpha) * ada_test\n",
    "print('Test prediction:',mean_squared_error(pred_test_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SecondTrain = pd.DataFrame(np.nan, index=np.arange(len(Xval)), columns=['RF','ADA'])\n",
    "\n",
    "SecondTrain['RF'] = rf.predict(Xval)\n",
    "SecondTrain['ADA'] = ada.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = RandomForestRegressor()\n",
    "meta.fit(SecondTrain,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_test = rf.predict(X_test)\n",
    "ada_test = ada.predict(X_test)\n",
    "\n",
    "FirstLevelPred = pd.DataFrame(np.nan, index=np.arange(len(X_test)), columns=['RF','ADA'])\n",
    "\n",
    "FirstLevelPred['RF'] = rf.predict(X_test)\n",
    "FirstLevelPred['ADA'] = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction: 11.358251999999998\n"
     ]
    }
   ],
   "source": [
    "final_pred = meta.predict(FirstLevelPred)\n",
    "\n",
    "print('Final prediction:',mean_squared_error(final_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X_full = data.data\n",
    "y_full = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, \n",
    "                                        random_state=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(X.shape[0], shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "print(cross_val_score(rf, X, y, cv=cv, scoring ='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "print(cross_val_score(lr, X, y, cv=cv, scoring ='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "voting = VotingClassifier(estimators=[('RF',rf),('LR',lr)], voting='soft')\n",
    "voting.fit(X, y)\n",
    "pred_voting = voting.predict(X_test)\n",
    "\n",
    "print('Accuracy on test:', accuracy_score(pred_voting,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "1) Разбейте X, y на тренировочную и валидационную части\n",
    "\n",
    "2) Сделайте предсказание с помощью блендинга (предсказывайте вероятности классов, а не сами классы - методом predict_proba)\n",
    "\n",
    "3) Сделайте предсказание с помощью стекинга (предсказывайте вероятности классов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Blending**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=135)\n",
    "pred_proba_rf = rf.predict_proba(X_test)\n",
    "pred_proba_lr = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mix_pred = 0.5 * (pred_proba_rf + pred_proba_lr)\n",
    "\n",
    "pred_final = [np.argmax(elem) for elem in mix_pred]\n",
    "\n",
    "print('Accuracy blending:', accuracy_score(pred_final, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовое решение для stacking\n",
    "\n",
    "Вернемся к задаче регрессии с датасетом Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [RandomForestRegressor]\n",
      "    ----\n",
      "    MEAN:     [0.07628205] + [0.02572902]\n",
      "    FULL:     [0.07600000]\n",
      "\n",
      "model  1:     [AdaBoostRegressor]\n",
      "    ----\n",
      "    MEAN:     [0.06089744] + [0.03525641]\n",
      "    FULL:     [0.06000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestRegressor(),AdaBoostRegressor()]\n",
    "\n",
    "S_train, S_test = stacking(models, X, y, X_test, regression=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = RandomForestRegressor()\n",
    "meta.fit(S_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction: 0.0639387661566127\n"
     ]
    }
   ],
   "source": [
    "final_pred = meta.predict(S_test)\n",
    "\n",
    "print('Final prediction:',mean_squared_error(final_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Используйте библиотеку vecstack для решения задачи классификации Iris с помощью stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [LogisticRegression]\n",
      "    ----\n",
      "    MEAN:     [0.14583333] + [0.17052818]\n",
      "    FULL:     [0.14000000]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.06089744] + [0.03525641]\n",
      "    FULL:     [0.06000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X_full = data.data\n",
    "y_full = data.target\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, random_state=135)\n",
    "models = [LogisticRegression(), RandomForestClassifier()]\n",
    "S_train, S_test = stacking(models, X, y, X_test, regression=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = LogisticRegression()\n",
    "meta.fit(S_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction: 0.19\n"
     ]
    }
   ],
   "source": [
    "final_pred = meta.predict(S_test)\n",
    "\n",
    "print('Final prediction:',mean_squared_error(final_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Решите задачу с данными train_medium.csv, test_medium.csv, используя stacking и/или blending нескольких алгоритмов. Сравните полученное качество (на кросс-валидации) с качеством, полученным с помощью xgboost, catboost, lightgbm в отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
