{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-27 16:45:36--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.1\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/fnpq3z4bcnoktiv/positive.csv [переход]\n",
      "--2019-04-27 16:45:37--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com/cd/0/inline/Af1brmj83-LYAaqYcP0uv_DGQu0ckSXb8ilhizfNCUTz7rK5Fhe7XDxshd1A67tWUN_-NpirS15dRlB8ufKJMrvYL8tO--MHR6PSfHhb5uhIBoJb7w3sAcQstx7ye7sp_Lk/file# [переход]\n",
      "--2019-04-27 16:45:37--  https://uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com/cd/0/inline/Af1brmj83-LYAaqYcP0uv_DGQu0ckSXb8ilhizfNCUTz7rK5Fhe7XDxshd1A67tWUN_-NpirS15dRlB8ufKJMrvYL8tO--MHR6PSfHhb5uhIBoJb7w3sAcQstx7ye7sp_Lk/file\n",
      "Распознаётся uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com (uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com)… 162.125.70.6\n",
      "Подключение к uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com (uc1acd8994049c7fa4078e9924d2.dl.dropboxusercontent.com)|162.125.70.6|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 26233379 (25M) [text/plain]\n",
      "Сохранение в: «positive.csv?dl=0»\n",
      "\n",
      "positive.csv?dl=0   100%[===================>]  25,02M  7,77MB/s    за 3,2s    \n",
      "\n",
      "2019-04-27 16:45:42 (7,77 MB/s) - «positive.csv?dl=0» сохранён [26233379/26233379]\n",
      "\n",
      "--2019-04-27 16:45:42--  http://positive.csv/\n",
      "Распознаётся positive.csv (positive.csv)… ошибка: nodename nor servname provided, or not known.\n",
      "wget: не удаётся разрешить адрес «positive.csv»\n",
      "ЗАВЕРШЕНО --2019-04-27 16:45:42--\n",
      "Общее время: 5,6s\n",
      "Загружено: 1 файлов, 25M за 3,2s (7,77 MB/s)\n",
      "--2019-04-27 16:45:42--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.1\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/r6u59ljhhjdg6j0/negative.csv [переход]\n",
      "--2019-04-27 16:45:42--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com/cd/0/inline/Af34uRRDLHk7ZBWNqyFAXnkXajj10lj7EltjGpgHNIn5R3M_yjh8ZV8ZXClZsuYJF8e5CqRbb4Cp9oBGlI_m9WrwAhvDWx79MwkSJ2JjnCL6XwUCXnfFd1Baz-3f1p9qtzU/file# [переход]\n",
      "--2019-04-27 16:45:43--  https://uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com/cd/0/inline/Af34uRRDLHk7ZBWNqyFAXnkXajj10lj7EltjGpgHNIn5R3M_yjh8ZV8ZXClZsuYJF8e5CqRbb4Cp9oBGlI_m9WrwAhvDWx79MwkSJ2JjnCL6XwUCXnfFd1Baz-3f1p9qtzU/file\n",
      "Распознаётся uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com (uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com)… 162.125.70.6\n",
      "Подключение к uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com (uc298161f027c66d5ed66cba46f9.dl.dropboxusercontent.com)|162.125.70.6|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 24450101 (23M) [text/plain]\n",
      "Сохранение в: «negative.csv?dl=0»\n",
      "\n",
      "negative.csv?dl=0   100%[===================>]  23,32M  8,12MB/s    за 2,9s    \n",
      "\n",
      "2019-04-27 16:45:47 (8,12 MB/s) - «negative.csv?dl=0» сохранён [24450101/24450101]\n",
      "\n",
      "--2019-04-27 16:45:47--  http://negative.csv/\n",
      "Распознаётся negative.csv (negative.csv)… ошибка: nodename nor servname provided, or not known.\n",
      "wget: не удаётся разрешить адрес «negative.csv»\n",
      "ЗАВЕРШЕНО --2019-04-27 16:45:47--\n",
      "Общее время: 5,0s\n",
      "Загружено: 1 файлов, 23M за 2,9s (8,12 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0' positive.csv\n",
    "!wget 'https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0' negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive.csv?dl=0',header=None,encoding='utf-8',delimiter=';')\n",
    "negative = pd.read_csv('negative.csv?dl=0',header=None,encoding='utf-8',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive=positive[[positive.columns[3]]]\n",
    "negative=negative[[negative.columns[3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive['target']=1\n",
    "negative['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive.columns=['text','target']\n",
    "negative.columns=['text','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  @first_timee хоть я и школота, но поверь, у на...       1\n",
       "1  Да, все-таки он немного похож на него. Но мой ...       1\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...       1\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...       1\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set = pd.concat([positive,negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(full_set['text'],full_set.target.values,test_size=0.2,shuffle=True,random_state=2121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(TfidfVectorizer(ngram_range=(1,2)),MultinomialNB())\n",
    "clf.fit(x_train,y_train)\n",
    "preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7739546366301496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь опробуем на этих же данных простейшую сеть с предобученными ембедингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-27 16:46:42--  http://files.deeppavlov.ai/embeddings/ft_native_300_ru_twitter_nltk_word_tokenize.vec\n",
      "Распознаётся files.deeppavlov.ai (files.deeppavlov.ai)… 93.175.29.74\n",
      "Подключение к files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 2767469831 (2,6G) [application/octet-stream]\n",
      "Сохранение в: «ft_native_300_ru_twitter_nltk_word_tokenize.vec»\n",
      "\n",
      "ft_native_300_ru_tw 100%[===================>]   2,58G  2,56MB/s    за 17m 56s \n",
      "\n",
      "2019-04-27 17:04:38 (2,45 MB/s) - «ft_native_300_ru_twitter_nltk_word_tokenize.vec» сохранён [2767469831/2767469831]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.deeppavlov.ai/embeddings/ft_native_300_ru_twitter_nltk_word_tokenize.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed295d0b481c480d9154320cdc9fbfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('ft_native_300_ru_twitter_nltk_word_tokenize.vec')\n",
    "embedding_values = {}\n",
    "for line in tqdm_notebook(f):\n",
    "    value = line.replace('\\n','').split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:-1],dtype = 'float32')\n",
    "    embedding_values[word]=coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291376 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(full_set['text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2158bbb0f49e43069f10baf882efb8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, 100),dtype=np.float32)\n",
    "sum_finding=0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    try:\n",
    "        embedding_vector = embedding_values[word]\n",
    "        sum_finding=sum_finding+1\n",
    "    except:\n",
    "        embedding_vector = embedding_values[\"unknown\"]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нашли векторов -  147597\n"
     ]
    }
   ],
   "source": [
    "print('Нашли векторов - ',sum_finding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готовим модель...\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Обучаем...\n",
      "Train on 181467 samples, validate on 45367 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "181467/181467 [==============================] - 62s 341us/sample - loss: 0.5614 - acc: 0.7033 - val_loss: 0.5113 - val_acc: 0.7413\n",
      "Epoch 2/25\n",
      "181467/181467 [==============================] - 60s 330us/sample - loss: 0.5122 - acc: 0.7395 - val_loss: 0.4831 - val_acc: 0.7600\n",
      "Epoch 3/25\n",
      "181467/181467 [==============================] - 60s 331us/sample - loss: 0.4947 - acc: 0.7505 - val_loss: 0.4886 - val_acc: 0.7518\n",
      "Epoch 4/25\n",
      "181467/181467 [==============================] - 59s 326us/sample - loss: 0.4834 - acc: 0.7590 - val_loss: 0.4775 - val_acc: 0.7604\n",
      "Epoch 5/25\n",
      "181467/181467 [==============================] - 60s 330us/sample - loss: 0.4748 - acc: 0.7650 - val_loss: 0.4771 - val_acc: 0.7599\n",
      "Epoch 6/25\n",
      "181467/181467 [==============================] - 62s 341us/sample - loss: 0.4689 - acc: 0.7679 - val_loss: 0.4595 - val_acc: 0.7754\n",
      "Epoch 7/25\n",
      "181467/181467 [==============================] - 62s 341us/sample - loss: 0.4638 - acc: 0.7718 - val_loss: 0.4522 - val_acc: 0.7794\n",
      "Epoch 8/25\n",
      "181467/181467 [==============================] - 64s 355us/sample - loss: 0.4610 - acc: 0.7742 - val_loss: 0.4547 - val_acc: 0.7765\n",
      "Epoch 9/25\n",
      "181467/181467 [==============================] - 65s 356us/sample - loss: 0.4572 - acc: 0.7766 - val_loss: 0.4489 - val_acc: 0.7821\n",
      "Epoch 10/25\n",
      "181467/181467 [==============================] - 64s 350us/sample - loss: 0.4537 - acc: 0.7787 - val_loss: 0.4512 - val_acc: 0.7798\n",
      "Epoch 11/25\n",
      "181467/181467 [==============================] - 63s 347us/sample - loss: 0.4511 - acc: 0.7803 - val_loss: 0.4463 - val_acc: 0.7845\n",
      "Epoch 12/25\n",
      "181467/181467 [==============================] - 9454s 52ms/sample - loss: 0.4487 - acc: 0.7822 - val_loss: 0.4432 - val_acc: 0.7855\n",
      "Epoch 13/25\n",
      "181467/181467 [==============================] - 130s 714us/sample - loss: 0.4468 - acc: 0.7840 - val_loss: 0.4433 - val_acc: 0.7851\n",
      "Epoch 14/25\n",
      "181467/181467 [==============================] - 87s 482us/sample - loss: 0.4442 - acc: 0.7847 - val_loss: 0.4412 - val_acc: 0.7875\n",
      "Epoch 15/25\n",
      "181467/181467 [==============================] - 72s 395us/sample - loss: 0.4428 - acc: 0.7852 - val_loss: 0.4400 - val_acc: 0.7878\n",
      "Epoch 16/25\n",
      "181467/181467 [==============================] - 72s 398us/sample - loss: 0.4416 - acc: 0.7868 - val_loss: 0.4399 - val_acc: 0.7878\n",
      "Epoch 17/25\n",
      "181467/181467 [==============================] - 72s 399us/sample - loss: 0.4384 - acc: 0.7895 - val_loss: 0.4409 - val_acc: 0.7881\n",
      "Epoch 18/25\n",
      "181467/181467 [==============================] - 66s 364us/sample - loss: 0.4371 - acc: 0.7893 - val_loss: 0.4362 - val_acc: 0.7911\n",
      "Epoch 19/25\n",
      "181467/181467 [==============================] - 67s 368us/sample - loss: 0.4364 - acc: 0.7898 - val_loss: 0.4376 - val_acc: 0.7908\n",
      "Epoch 20/25\n",
      "181467/181467 [==============================] - 57s 314us/sample - loss: 0.4348 - acc: 0.7909 - val_loss: 0.4409 - val_acc: 0.7875\n",
      "Epoch 21/25\n",
      "181467/181467 [==============================] - 62s 340us/sample - loss: 0.4335 - acc: 0.7914 - val_loss: 0.4362 - val_acc: 0.7928\n",
      "Epoch 22/25\n",
      "181467/181467 [==============================] - 71s 393us/sample - loss: 0.4321 - acc: 0.7931 - val_loss: 0.4370 - val_acc: 0.7906\n",
      "Epoch 23/25\n",
      "181467/181467 [==============================] - 64s 351us/sample - loss: 0.4318 - acc: 0.7931 - val_loss: 0.4345 - val_acc: 0.7928\n",
      "Epoch 24/25\n",
      "181467/181467 [==============================] - 65s 356us/sample - loss: 0.4309 - acc: 0.7938 - val_loss: 0.4360 - val_acc: 0.7915\n",
      "Epoch 25/25\n",
      "181467/181467 [==============================] - 70s 388us/sample - loss: 0.4306 - acc: 0.7939 - val_loss: 0.4332 - val_acc: 0.7950\n",
      "45367/45367 [==============================] - 6s 126us/sample - loss: 0.4332 - acc: 0.7950\n",
      "Тест score: 0.43318050588893403\n",
      "Тест accuracy: 0.79498315\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 40  \n",
    "batch_size = 256 \n",
    "\n",
    "print('Готовим модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    len(word_index)+1,\n",
    "    100,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=maxlen,\n",
    "    trainable=False\n",
    "))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(GRU(32)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-3,clipnorm=5,clipvalue=5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "print('Обучаем...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=25,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Тест score:', score)\n",
    "print('Тест accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
