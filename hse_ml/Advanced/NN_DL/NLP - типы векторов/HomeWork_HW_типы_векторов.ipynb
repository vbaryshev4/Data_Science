{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Необходимо обучить регрессионную модель (предсказание популярности статьи на Хабре) - за бейзлайн возьмите tf-idf + линейная модель:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(s):\n",
    "    for c in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~—«»':\n",
    "        s = s.replace(c, \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    return \" \".join((morph.parse(i)[0].normal_form for i in s.lower().split() if len(i) > 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tags(s):\n",
    "    return ' '.join(remove_punct(s).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убиваем линки. \n",
    "# Линки бывают разные, поэтому можно по-рахно их размечать в тексте (линк, картинка)\n",
    "def delete_links(s):\n",
    "    return re.sub(r\"<.*?\\>\",\" link \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_content.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['_id', 'url', 'date', 'hub', 'png', 'nick', 'name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['tags', 'title', 'hubs_title', 'description', 'content']:\n",
    "    if c == 'tags':\n",
    "        data[c] = data[c].map(join_tags)\n",
    "    if c == 'content':\n",
    "        data[c] = data[c].map(delete_links)\n",
    "    data[c] = data[c].map(remove_punct)\n",
    "    data[c] = data[c].map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tokened_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и уменщение размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tokened_data.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>hubs_title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>favs_lognorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eeepc asus эльдорадо</td>\n",
       "      <td>eeepc продажа правда</td>\n",
       "      <td>железо</td>\n",
       "      <td>итак если назад отписаться продажа появиться m...</td>\n",
       "      <td>итак если назад link отписаться link продажа п...</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midnight commander diffview merge filemanager</td>\n",
       "      <td>релиз midnight commander 4705</td>\n",
       "      <td>чёрный дыра</td>\n",
       "      <td>спустя месяц упорный труд выйти новый версия к...</td>\n",
       "      <td>спустя месяц упорный труд выйти новый версия к...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>бизнесмодель бизнесмоделирование</td>\n",
       "      <td>шаг постройка правильный бизнесмодеть</td>\n",
       "      <td>интернетмаркетинг</td>\n",
       "      <td>большинство предприниматель сосредотачиваться ...</td>\n",
       "      <td>link большинство предприниматель сосредотачива...</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python flask mongodb petproject</td>\n",
       "      <td>thunderargs практика использование часть</td>\n",
       "      <td>программирование</td>\n",
       "      <td>история создание часть добрый день вкратце нап...</td>\n",
       "      <td>link история создание link link link часть lin...</td>\n",
       "      <td>3.688879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>карма usability идея хабра habrahabr</td>\n",
       "      <td>изменение карма пользователь нулевой активность</td>\n",
       "      <td>хабрахабра</td>\n",
       "      <td>назад наконец получить хороший человек долгожд...</td>\n",
       "      <td>назад наконец получить хороший человек долгожд...</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tags  \\\n",
       "0                           eeepc asus эльдорадо   \n",
       "1  midnight commander diffview merge filemanager   \n",
       "2               бизнесмодель бизнесмоделирование   \n",
       "3                python flask mongodb petproject   \n",
       "4           карма usability идея хабра habrahabr   \n",
       "\n",
       "                                             title         hubs_title  \\\n",
       "0                             eeepc продажа правда             железо   \n",
       "1                    релиз midnight commander 4705        чёрный дыра   \n",
       "2            шаг постройка правильный бизнесмодеть  интернетмаркетинг   \n",
       "3         thunderargs практика использование часть   программирование   \n",
       "4  изменение карма пользователь нулевой активность         хабрахабра   \n",
       "\n",
       "                                         description  \\\n",
       "0  итак если назад отписаться продажа появиться m...   \n",
       "1  спустя месяц упорный труд выйти новый версия к...   \n",
       "2  большинство предприниматель сосредотачиваться ...   \n",
       "3  история создание часть добрый день вкратце нап...   \n",
       "4  назад наконец получить хороший человек долгожд...   \n",
       "\n",
       "                                             content  favs_lognorm  \n",
       "0  итак если назад link отписаться link продажа п...      2.484907  \n",
       "1  спустя месяц упорный труд выйти новый версия к...      0.000000  \n",
       "2  link большинство предприниматель сосредотачива...      3.496508  \n",
       "3  link история создание link link link часть lin...      3.688879  \n",
       "4  назад наконец получить хороший человек долгожд...      0.693147  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_limit = 130 # отрезать первые {cut_limit} слов от строки\n",
    "def cut_content(s):\n",
    "    splitted = s.split()\n",
    "    if len(splitted) > cut_limit:\n",
    "        return ' '.join(splitted[:cut_limit])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].map(cut_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>hubs_title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>favs_lognorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eeepc asus эльдорадо</td>\n",
       "      <td>eeepc продажа правда</td>\n",
       "      <td>железо</td>\n",
       "      <td>итак если назад отписаться продажа появиться m...</td>\n",
       "      <td>итак если назад link отписаться link продажа п...</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midnight commander diffview merge filemanager</td>\n",
       "      <td>релиз midnight commander 4705</td>\n",
       "      <td>чёрный дыра</td>\n",
       "      <td>спустя месяц упорный труд выйти новый версия к...</td>\n",
       "      <td>спустя месяц упорный труд выйти новый версия к...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>бизнесмодель бизнесмоделирование</td>\n",
       "      <td>шаг постройка правильный бизнесмодеть</td>\n",
       "      <td>интернетмаркетинг</td>\n",
       "      <td>большинство предприниматель сосредотачиваться ...</td>\n",
       "      <td>link большинство предприниматель сосредотачива...</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python flask mongodb petproject</td>\n",
       "      <td>thunderargs практика использование часть</td>\n",
       "      <td>программирование</td>\n",
       "      <td>история создание часть добрый день вкратце нап...</td>\n",
       "      <td>link история создание link link link часть lin...</td>\n",
       "      <td>3.688879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>карма usability идея хабра habrahabr</td>\n",
       "      <td>изменение карма пользователь нулевой активность</td>\n",
       "      <td>хабрахабра</td>\n",
       "      <td>назад наконец получить хороший человек долгожд...</td>\n",
       "      <td>назад наконец получить хороший человек долгожд...</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tags  \\\n",
       "0                           eeepc asus эльдорадо   \n",
       "1  midnight commander diffview merge filemanager   \n",
       "2               бизнесмодель бизнесмоделирование   \n",
       "3                python flask mongodb petproject   \n",
       "4           карма usability идея хабра habrahabr   \n",
       "\n",
       "                                             title         hubs_title  \\\n",
       "0                             eeepc продажа правда             железо   \n",
       "1                    релиз midnight commander 4705        чёрный дыра   \n",
       "2            шаг постройка правильный бизнесмодеть  интернетмаркетинг   \n",
       "3         thunderargs практика использование часть   программирование   \n",
       "4  изменение карма пользователь нулевой активность         хабрахабра   \n",
       "\n",
       "                                         description  \\\n",
       "0  итак если назад отписаться продажа появиться m...   \n",
       "1  спустя месяц упорный труд выйти новый версия к...   \n",
       "2  большинство предприниматель сосредотачиваться ...   \n",
       "3  история создание часть добрый день вкратце нап...   \n",
       "4  назад наконец получить хороший человек долгожд...   \n",
       "\n",
       "                                             content  favs_lognorm  \n",
       "0  итак если назад link отписаться link продажа п...      2.484907  \n",
       "1  спустя месяц упорный труд выйти новый версия к...      0.000000  \n",
       "2  link большинство предприниматель сосредотачива...      3.496508  \n",
       "3  link история создание link link link часть lin...      3.688879  \n",
       "4  назад наконец получить хороший человек долгожд...      0.693147  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data[data.columns[~data.columns.isin(['favs_lognorm'])]], \n",
    "    data['favs_lognorm'],\n",
    "    test_size=0.19,\n",
    "    shuffle=True,\n",
    "    random_state=2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная модель на TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "trains = []\n",
    "tests = []\n",
    "for c in ['tags', 'title', 'hubs_title', 'description', 'content']:\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    X_tr = coo_matrix(vectorizer.fit_transform(x_train[c]))\n",
    "    X_te = coo_matrix(vectorizer.transform(x_test[c]))\n",
    "    trains.append(X_tr)\n",
    "    tests.append(X_te)\n",
    "tfidf_x_train = hstack(trains)\n",
    "tfidf_x_test = hstack(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(LinearRegression(n_jobs=-1))\n",
    "clf.fit(tfidf_x_train, y_train.values)\n",
    "preds = clf.predict(tfidf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2246443986027111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test.values, preds) #Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сетка на эмбедингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Эмбеддинг на твиттере (работает хуже)\n",
    "# !wget http://files.deeppavlov.ai/embeddings/ft_native_300_ru_twitter_nltk_word_tokenize.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Эмбеддинг на вики и ленте (работает лучше)\n",
    "# !wget http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_lemmatize/ft_native_300_ru_wiki_lenta_lemmatize.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-17 10:17:18--  http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_lower_case/ft_native_300_ru_wiki_lenta_lower_case.vec\n",
      "Распознаётся files.deeppavlov.ai (files.deeppavlov.ai)… 93.175.29.74\n",
      "Подключение к files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 4140857273 (3,9G) [application/octet-stream]\n",
      "Сохранение в: «ft_native_300_ru_wiki_lenta_lower_case.vec»\n",
      "\n",
      "ft_native_300_ru_wi 100%[===================>]   3,86G  16,3MB/s    за 4m 24s  \n",
      "\n",
      "2019-05-17 10:21:43 (14,9 MB/s) - «ft_native_300_ru_wiki_lenta_lower_case.vec» сохранён [4140857273/4140857273]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Эмбеддинг на вики и ленте (работает ???? Попробовать)\n",
    "# !wget http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_lower_case/ft_native_300_ru_wiki_lenta_lower_case.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('ft_native_300_ru_twitter_nltk_word_tokenize.vec')\n",
    "# f = open('ft_native_300_ru_wiki_lenta_lemmatize.vec')\n",
    "f = open('ft_native_300_ru_wiki_lenta_lower_case.vec')\n",
    "\n",
    "embedding_values = {}\n",
    "for line in f:\n",
    "    value = line.replace('\\n','').split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:-1],dtype = 'float32')\n",
    "    embedding_values[word]=coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_max_len(s):\n",
    "    return len(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_matrix(word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, 300),dtype=np.float32)\n",
    "    sum_finding = 0\n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            embedding_vector = embedding_values[word]\n",
    "            sum_finding = sum_finding+1\n",
    "        except:\n",
    "            embedding_vector = embedding_values[\"unknown\"]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51921 unique tokens.\n",
      "Found 51037 unique tokens.\n",
      "Found 411 unique tokens.\n",
      "Found 84503 unique tokens.\n",
      "Found 295086 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "embedding_matrix = []\n",
    "l_word_ind = 0\n",
    "\n",
    "for c in ['tags', 'title', 'hubs_title', 'description', 'content']:\n",
    "    maxlen = x_train[c].map(count_max_len).max()\n",
    "    tokenizer = Tokenizer(num_words=1000000)\n",
    "    tokenizer.fit_on_texts(x_train[c])\n",
    "    sequences_train = tokenizer.texts_to_sequences(x_train[c])\n",
    "    sequences_test = tokenizer.texts_to_sequences(x_test[c])\n",
    "    pad_train = pad_sequences(sequences_train, maxlen=maxlen)\n",
    "    pad_test = pad_sequences(sequences_test, maxlen=maxlen)\n",
    "    X_train.append(pad_train)\n",
    "    X_test.append(pad_test)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    \n",
    "    emb_matrix = get_embed_matrix(word_index)\n",
    "    embedding_matrix.append(emb_matrix)\n",
    "    \n",
    "    l_word_ind += len(word_index)+1\n",
    "    \n",
    "\n",
    "X_train = np.hstack(X_train)\n",
    "X_test = np.hstack(X_test)\n",
    "embedding_matrix = np.vstack(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готовим модель...\n",
      "WARNING:tensorflow:From /home/vlad1/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/vlad1/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/vlad1/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Обучаем...\n",
      "Train on 87420 samples, validate on 20507 samples\n",
      "WARNING:tensorflow:From /home/vlad1/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "87420/87420 [==============================] - 123s 1ms/sample - loss: 1.7694 - mean_squared_error: 1.7694 - val_loss: 1.6114 - val_mean_squared_error: 1.6114\n",
      "Epoch 2/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.3142 - mean_squared_error: 1.3142 - val_loss: 1.3938 - val_mean_squared_error: 1.3938\n",
      "Epoch 3/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.2344 - mean_squared_error: 1.2344 - val_loss: 1.4362 - val_mean_squared_error: 1.4362\n",
      "Epoch 4/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.2275 - mean_squared_error: 1.2275 - val_loss: 1.3205 - val_mean_squared_error: 1.3205\n",
      "Epoch 5/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.1984 - mean_squared_error: 1.1984 - val_loss: 1.3778 - val_mean_squared_error: 1.3778\n",
      "Epoch 6/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.1455 - mean_squared_error: 1.1455 - val_loss: 1.3125 - val_mean_squared_error: 1.3125\n",
      "Epoch 7/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.1175 - mean_squared_error: 1.1175 - val_loss: 1.3361 - val_mean_squared_error: 1.3361\n",
      "Epoch 8/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.0902 - mean_squared_error: 1.0902 - val_loss: 1.2595 - val_mean_squared_error: 1.2595\n",
      "Epoch 9/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.1345 - mean_squared_error: 1.1345 - val_loss: 1.3658 - val_mean_squared_error: 1.3658\n",
      "Epoch 10/10\n",
      "87420/87420 [==============================] - 122s 1ms/sample - loss: 1.1215 - mean_squared_error: 1.1215 - val_loss: 1.2936 - val_mean_squared_error: 1.2936\n",
      "20507/20507 [==============================] - 11s 552us/sample - loss: 1.2936 - mean_squared_error: 1.2936\n",
      "Тест score: 1.2936269121725312\n",
      "Тест mse: 1.2936268\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1000) \n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ep = 10\n",
    "batch_size = 256\n",
    "\n",
    "print('Готовим модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    l_word_ind,\n",
    "    300,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=X_train.shape[1],\n",
    "    trainable=False\n",
    "))\n",
    "\n",
    "'''\n",
    "    model.add(SpatialDropout1D(0.22))\n",
    "    model.add(Bidirectional(SimpleRNN(64)))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "'''\n",
    "\n",
    "# model.add(SpatialDropout1D(0.1))\n",
    "# model.add(Bidirectional(LSTM(32)))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "model.add(SpatialDropout1D(0.04)) \n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(lr=1e-2, clipnorm=4, clipvalue=4), # Взрывается градиент. Градиентклиппинг во исправление ситации.\n",
    "    metrics=['mean_squared_error'])\n",
    "\n",
    "print('Обучаем...')\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train.values, \n",
    "    batch_size=batch_size, \n",
    "    epochs=ep, \n",
    "    validation_data=(X_test, y_test.values))\n",
    "\n",
    "score, mse = model.evaluate(X_test, y_test.values,\n",
    "                            batch_size=batch_size)\n",
    "print('Тест score:', score)\n",
    "print('Тест mse:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
