{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Композиции деревьев\n",
    "#### Сравнение композиционных методов над решающими деревьями\n",
    "\n",
    "Загрузим датасет из соревнования [BNP Paribas Cardif Claims Management](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/leaderboard). Возьмем из него первые 10к объектов, оставим только вещественные признаки, а пропуски заменим нулями. Разобьем выборку на обучение и контроль в соотношении 7:3.\n",
    "\n",
    "1. С помощью cross_val_score с cv=3 оценим качество (accuracy) следующих классификаторов на обучающей выборке:\n",
    "    * DecisionTreeClassifier\n",
    "    * BaggingClassifier со 100 деревьями\n",
    "    * RandomForestClassifier со 100 деревьями\n",
    "    \n",
    "Значение получается шумное, но в целом должно получиться, что качество возрастает с каждым следующим алгоритмом. Этот пример демонстрирует, что RandomForest — это более сложный алгоритм, чем бэггинг. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1       NaN       NaN  C       NaN   9.191265       NaN       NaN   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1       NaN       NaN  C       NaN        NaN       NaN       NaN   \n",
       "\n",
       "         v8    ...         v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941    ...     8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630    ...          NaN       NaN  0.598896    AF       NaN       NaN   \n",
       "2  0.019645    ...     9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947    ...     7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4       NaN    ...          NaN       NaN       NaN     Z       NaN       NaN   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0       NaN       NaN  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_NAME= 'train.csv'\n",
    "COUNT_OBJECTS = 10000\n",
    "\n",
    "data = pd.read_csv(FILE_NAME, nrows=COUNT_OBJECTS)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 133)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7562\n",
       "0    2438\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data[\"target\"]\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    108\n",
       "object      19\n",
       "int64        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_numerical_column_names = list(filter(lambda elem : data[elem].dtype == 'float64',  data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>...</th>\n",
       "      <th>v120</th>\n",
       "      <th>v121</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>16.434108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059603</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138728</td>\n",
       "      <td>2.238806</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166281</td>\n",
       "      <td>1.956521</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1  0.000000  0.000000  0.000000   9.191265  0.000000  0.000000  2.301630   \n",
       "2  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          v9       v10        v11    ...         v120      v121      v122  \\\n",
       "0   9.999999  0.503281  16.434108    ...     1.059603  0.803572  8.000000   \n",
       "1   0.000000  1.312910   0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  12.666667  0.765864  14.756098    ...     2.138728  2.238806  9.333333   \n",
       "3   8.965516  6.542669  16.347483    ...     1.166281  1.956521  7.018256   \n",
       "4   0.000000  1.050328   0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\n",
       "       v123      v124      v126      v127      v128      v130      v131  \n",
       "0  1.989780  0.035754  1.804126  3.113719  2.024285  0.636365  2.857144  \n",
       "1  0.000000  0.598896  0.000000  0.000000  1.957825  0.000000  0.000000  \n",
       "2  2.477596  0.013452  1.773709  3.922193  1.120468  0.883118  1.176472  \n",
       "3  1.812795  0.002267  1.415230  2.954381  1.990847  1.677108  1.034483  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = data.loc[:, all_numerical_column_names].fillna(0)\n",
    "num_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(num_data, target, train_size=0.7, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7154298453457607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_DT = DecisionTreeClassifier(max_depth=10)\n",
    "model_DT_cross = cross_val_score(model_DT, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_DT_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7468566019897812\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier со 100 деревьями\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_Bagging = BaggingClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_Bagging_cross = cross_val_score(model_Bagging, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Bagging_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.41 s ± 321 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "0.7531428470684943\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier со 100 деревьями\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_Forest = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "%timeit model_Forest_cross = cross_val_score(model_Forest, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Forest_cross))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Число деревьев в случайном лесе\n",
    "В этой задаче рассмотрим, переобучаются ли композиционные алгоритмы с увеличением числа деревьев.\n",
    "\n",
    "Переберем значения от 20 до 1000-5000 деревьев с шагом 50, посчитаем accuracy на тестовой выборке для каждого числа деревьев и построем график зависимости качества от числа деревьев.\n",
    "\n",
    "Рекомендация.\n",
    "\n",
    "Если каждый раз обучать RandomForest с нуля, придётся обучить в общей сумме $20 + 70 + \\ldots + 5000$ деревьев, но можно обучить всего 5000 деревьев.\n",
    "\n",
    "Для этого в при создании объекта класса RandomForestClassifier нужно указать в том числе warm_start=True. Затем обучить алгоритм с помощью метода fit, использовать метод predict для классификации. После этого с помощью метода set_params изменить параметр n_estimators. Если к полученному объекту применить метод fit, внутри него будет обучаться только недостающее число деревьев.\n",
    "\n",
    "Переобучается ли случайный лес с увеличением числа деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112e4b160>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112bdca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trees_num = 1020\n",
    "model_Forest = RandomForestClassifier(max_depth=10, n_jobs=-1, warm_start=True)\n",
    "accuracies = []\n",
    "for i in range(20, trees_num, 10):\n",
    "    model_Forest.set_params(n_estimators=i)\n",
    "    # x_train, x_test, y_train, y_test\n",
    "    model_Forest.fit(x_train, y_train)\n",
    "    y_pred = model_Forest.predict(x_test)\n",
    "    r = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(r)\n",
    "\n",
    "plt.plot([i for i in range(20, trees_num, 10)], accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение градиентного бустинга\n",
    "\n",
    "А теперь попробуем обучить на тех же данных catboost — одну из реализаций градиентного бустинга. Подберем параметры на обучающем множестве с помощью кросс-валидации (хорошая [статья](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/) про тюнинг параметров). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.0356\n",
      "Learning rate set to 0.035602\n",
      "Learning rate set to 0.035602\n",
      "0.7604286228672893\n"
     ]
    }
   ],
   "source": [
    "model_Cat = CatBoostClassifier(iterations=700, verbose=False, thread_count=4)\n",
    "model_Cat_cross = cross_val_score(model_Cat, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Cat_cross))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(num_data, target, train_size=0.7, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вспомним, что изначально выбросили все категориальные признаки из датасета. Добавим категориальные признаки с количеством уникальных значений < 50 тремя способами:\n",
    "* как OHE признаки (готово)\n",
    "* как порядковые признаки (закодируйте с помощью LabelEncoder, порядок случайный) (готово)\n",
    "* как счетчики со сглаживанием (не понял что это. Можно ссылку?)\n",
    "\n",
    "1) Подберем в каждом из случаев оптимальные параметры метода. \n",
    "\n",
    "Должна ли меняться оптимальная глубина деревьев от способа кодирования категориальных признаков? \n",
    "Ответ: Чем больше признаков, тем больше глубина.\n",
    "\n",
    "Как меняется время, необходимое для обучения модели в зависимости от способа кодирования? Меняется в сторону уменьшения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    108\n",
       "object      19\n",
       "int64        5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_NAME = 'train.csv'\n",
    "COUNT_OBJECTS = 10000\n",
    "data = pd.read_csv(FILE_NAME, nrows=COUNT_OBJECTS)\n",
    "\n",
    "target = data[\"target\"]\n",
    "data = data.drop([\"target\"], axis=1)\n",
    "\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Маски по заголовкам\n",
    "all_numerical_column_names = list(filter(lambda elem : data[elem].dtype == 'float64',  data.columns))\n",
    "all_int_column_names = list(filter(lambda elem : data[elem].dtype == 'int64',  data.columns))\n",
    "all_object_column_names = list(filter(lambda elem : data[elem].dtype == 'object',  data.columns))\n",
    "\n",
    "# Разбивка data по типам и заполнение пропусков\n",
    "num_data = data.loc[:, all_numerical_column_names].fillna(0)\n",
    "int_data = data.loc[:, all_int_column_names].fillna(-1)\n",
    "obj_data = data.loc[:, all_object_column_names].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x10040 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Применим OneHoteEncoding только для категориальных целочисленных признаков\n",
    "ohencoder = OneHotEncoder(sparse = True)\n",
    "ohencoded_int_data = ohencoder.fit_transform(int_data)\n",
    "ohencoded_int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v3</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v47</th>\n",
       "      <th>v52</th>\n",
       "      <th>v56</th>\n",
       "      <th>v66</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4467</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1926</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>424</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2187</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v3   v22  v24  v30  v31  v47  v52  v56  v66  v71  v74  v75  v79  v91  v107  \\\n",
       "0   3  4467    2    3    1    2    6   60    2    2    1    3    4    0     4   \n",
       "1   3  2103    2    3    1    4    6   72    0    2    1    3    3    1     1   \n",
       "2   3  1926    4    0    1    2    5   13    0    0    1    1    4    6     2   \n",
       "3   3   424    3    3    2    2    7   34    0    2    1    3    1    1     1   \n",
       "4   3  2187    4    0    1    7    7    0    2    2    1    3    2    6     2   \n",
       "\n",
       "   v110  v112  v113  v125  \n",
       "0     1    15     0    22  \n",
       "1     0    21    16     7  \n",
       "2     1    19     0     6  \n",
       "3     1    10     0    64  \n",
       "4     0    20    16    89  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Применим LabelEncoder только для данных типа object\n",
    "le = preprocessing.LabelEncoder()\n",
    "le_obj_data = pd.DataFrame()\n",
    "for feature in obj_data.columns:\n",
    "    le_obj_data[feature]=le.fit_transform(obj_data[feature])\n",
    "le_obj_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>...</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>16.434108</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1  0.000000  0.000000  0.000000   9.191265  0.000000  0.000000  2.301630   \n",
       "2  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          v9       v10        v11  ...   v71  v74  v75  v79  v91  v107  v110  \\\n",
       "0   9.999999  0.503281  16.434108  ...     2    1    3    4    0     4     1   \n",
       "1   0.000000  1.312910   0.000000  ...     2    1    3    3    1     1     0   \n",
       "2  12.666667  0.765864  14.756098  ...     0    1    1    4    6     2     1   \n",
       "3   8.965516  6.542669  16.347483  ...     2    1    3    1    1     1     1   \n",
       "4   0.000000  1.050328   0.000000  ...     2    1    3    2    6     2     0   \n",
       "\n",
       "   v112  v113  v125  \n",
       "0    15     0    22  \n",
       "1    21    16     7  \n",
       "2    19     0     6  \n",
       "3    10     0    64  \n",
       "4    20    16    89  \n",
       "\n",
       "[5 rows x 10167 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединяем значения в общий датафрэйм\n",
    "X = pd.concat([num_data, pd.DataFrame(ohencoded_int_data.todense()), le_obj_data], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, train_size=0.7, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.81 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "0.7531428470684943\n"
     ]
    }
   ],
   "source": [
    "model_Forest = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "%timeit model_Forest_cross = cross_val_score(model_Forest, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Forest_cross))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    1) Модель без категориальных признаков\\n    7.41 s ± 321 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\\n    0.7531428470684943\\n    \\n    2) Модель с векторизованными категориальными признаками (OHT sparse=True)\\n    6.81 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\\n    0.7531428470684943\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    1) Модель без категориальных признаков\n",
    "    7.41 s ± 321 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    0.7531428470684943\n",
    "    \n",
    "    2) Модель с векторизованными категориальными признаками (OHT sparse=True)\n",
    "    6.81 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    0.7531428470684943\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "FILE_NAME = 'train.csv'\n",
    "COUNT_OBJECTS = 10000\n",
    "data = pd.read_csv(FILE_NAME)\n",
    "target = data[\"target\"]\n",
    "data = data.drop([\"target\"], axis=1)\n",
    "# Маски по заголовкам\n",
    "all_numerical_column_names = list(filter(lambda elem : data[elem].dtype == 'float64',  data.columns))\n",
    "all_int_column_names = list(filter(lambda elem : data[elem].dtype == 'int64',  data.columns))\n",
    "all_object_column_names = list(filter(lambda elem : data[elem].dtype == 'object',  data.columns))\n",
    "\n",
    "# Разбивка data по типам и заполнение пропусков\n",
    "num_data = data.loc[:, all_numerical_column_names].fillna(0)\n",
    "int_data = data.loc[:, all_int_column_names].fillna(-1)\n",
    "obj_data = data.loc[:, all_object_column_names].fillna('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def obj_to_int(df):\n",
    "    le_obj_data = pd.DataFrame()\n",
    "    for feature in df.columns:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le_obj_data[feature]=le.fit_transform(df[feature])\n",
    "    \n",
    "    return le_obj_data\n",
    "\n",
    "# Применим LabelEncoder только для данных типа object\n",
    "le_obj_data = obj_to_int(obj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>...</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>16.434108</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1  0.000000  0.000000  0.000000   9.191265  0.000000  0.000000  2.301630   \n",
       "2  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          v9       v10        v11  ...   v71  v74  v75  v79  v91  v107  v110  \\\n",
       "0   9.999999  0.503281  16.434108  ...     4    1    3    4    1     5     1   \n",
       "1   0.000000  1.312910   0.000000  ...     4    1    3    3    2     2     0   \n",
       "2  12.666667  0.765864  14.756098  ...     1    1    1    4    7     3     1   \n",
       "3   8.965516  6.542669  16.347483  ...     4    1    3    1    2     2     1   \n",
       "4   0.000000  1.050328   0.000000  ...     4    1    3    2    7     3     0   \n",
       "\n",
       "   v112  v113  v125  \n",
       "0    15     0    22  \n",
       "1    21    18     7  \n",
       "2    19     0     6  \n",
       "3    10     0    65  \n",
       "4    20    18    90  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединяем значения в общий датафрэйм\n",
    "X = pd.concat([num_data, int_data, le_obj_data], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    108\n",
       "int64       24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes.value_counts() # Проверка типов и количества данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(['ID', 'v22'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  счетчики со сглаживанием\n",
    "def counts(column, target, constanta):\n",
    "    c = constanta\n",
    "    count = dict()\n",
    "    for item in (np.unique(column)):\n",
    "        count[item]=(((column == item) & (target == 1)).sum() + c)/((column == item).sum() + c)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_processing(df, target, encoding_type=None):\n",
    "    \n",
    "    if encoding_type is 'OHE':\n",
    "        mask = list(filter(lambda elem : df[elem].dtype == 'int64',  df.columns))\n",
    "        ohencoder = OneHotEncoder(categorical_features=[x in mask for x in df.columns])\n",
    "        X_encoded = ohencoder.fit_transform(df)\n",
    "        result = pd.DataFrame(X_encoded.todense(), index=df.index)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(result, target, test_size = 0.30, random_state = 17)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    elif encoding_type == 'LE':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.30, random_state = 17)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "                                                            \n",
    "    elif encoding_type == 'counts':\n",
    "        categorical_columns = list(filter(lambda elem : df[elem].dtype == 'int64',  df.columns))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.30, random_state = 17)\n",
    "        for column in categorical_columns:\n",
    "            count_dict = counts(X_train[column], y_train, 1)\n",
    "            X_train[column] = X_train[column].map(count_dict)\n",
    "            X_test[column] = X_test[column].map(count_dict)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "                \n",
    "        \n",
    "        # Применить counts(вызывать из препроцессинга) к категориальным столбцам \n",
    "        # X (проитеррироваться по категориальным столбцам)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_2 = X.copy()\n",
    "X_train, X_test, y_train, y_test = pre_processing(X_2, target, encoding_type='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    TODO: \\n    1) Применить counts(вызывать из препроцессинга) к категориальным столбцам X(проитеррироваться по категориальным столбцам)\\n    2) получаем словари значений счетчиков (словари с вероятностями)\\n    3) применяем на столбцах признаков X. Меняем инты и обджекты на словари с вероятностями\\n    4) Построить три раза деревья(время, валскор) на голом Х, на Х+ОНТ и на Х+счетчики(каунтс).\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    TODO: \n",
    "    1) Применить counts(вызывать из препроцессинга) к категориальным столбцам X(проитеррироваться по категориальным столбцам)\n",
    "    2) получаем словари значений счетчиков (словари с вероятностями)\n",
    "    3) применяем на столбцах признаков X. Меняем инты и обджекты на словари с вероятностями\n",
    "    4) Построить три раза деревья(время, валскор) на голом Х, на Х+ОНТ и на Х+счетчики(каунтс).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.199676\n",
      "Learning rate set to 0.199676\n",
      "LE 0.777704188743377\n",
      "Learning rate set to 0.199676\n",
      "Learning rate set to 0.199676\n",
      "OHE 0.7783914825552334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.199676\n",
      "Learning rate set to 0.199676\n",
      "counts 0.7775542337298811\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "for method in ['LE', 'OHE', 'counts']:\n",
    "    x_train, x_test, y_train, y_test = pre_processing(X, target, encoding_type=method)\n",
    "    model_Cat = CatBoostClassifier(iterations=200, verbose=False, thread_count=4)\n",
    "    model_Cat_cross = cross_val_score(model_Cat, x_train, y_train, cv=2, n_jobs=-1, scoring='accuracy')\n",
    "    print(method, np.mean(model_Cat_cross))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(filter(lambda elem : X[elem].dtype == 'int64',  X.columns))\n",
    "categorical_features=[i for i, x in enumerate(X.columns) if x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.246178\n",
      "LE <bound method CatBoostClassifier.score of <catboost.core.CatBoostClassifier object at 0x11a9b3a90>>\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pre_processing(X, target, encoding_type='LE')\n",
    "model_Cat = CatBoostClassifier(iterations=200, verbose=False, thread_count=4)\n",
    "model_Cat.fit(x_train, y_train, cat_features=categorical_features)\n",
    "print('LE', model_Cat.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929848091669826"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
