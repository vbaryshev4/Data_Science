{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Композиции деревьев\n",
    "#### Сравнение композиционных методов над решающими деревьями\n",
    "\n",
    "Загрузим датасет из соревнования [BNP Paribas Cardif Claims Management](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/leaderboard). Возьмем из него первые 10к объектов, оставим только вещественные признаки, а пропуски заменим нулями. Разобьем выборку на обучение и контроль в соотношении 7:3.\n",
    "\n",
    "1. С помощью cross_val_score с cv=3 оценим качество (accuracy) следующих классификаторов на обучающей выборке:\n",
    "    * DecisionTreeClassifier\n",
    "    * BaggingClassifier со 100 деревьями\n",
    "    * RandomForestClassifier со 100 деревьями\n",
    "    \n",
    "Значение получается шумное, но в целом должно получиться, что качество возрастает с каждым следующим алгоритмом. Этот пример демонстрирует, что RandomForest — это более сложный алгоритм, чем бэггинг. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1       NaN       NaN  C       NaN   9.191265       NaN       NaN   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1       NaN       NaN  C       NaN        NaN       NaN       NaN   \n",
       "\n",
       "         v8    ...         v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941    ...     8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630    ...          NaN       NaN  0.598896    AF       NaN       NaN   \n",
       "2  0.019645    ...     9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947    ...     7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4       NaN    ...          NaN       NaN       NaN     Z       NaN       NaN   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0       NaN       NaN  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_NAME= 'train.csv'\n",
    "COUNT_OBJECTS = 10000\n",
    "\n",
    "data = pd.read_csv(FILE_NAME, nrows=COUNT_OBJECTS)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 133)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7562\n",
       "0    2438\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data[\"target\"]\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    108\n",
       "object      19\n",
       "int64        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_numerical_column_names = list(filter(lambda elem : data[elem].dtype == 'float64',  data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>...</th>\n",
       "      <th>v120</th>\n",
       "      <th>v121</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>16.434108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059603</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138728</td>\n",
       "      <td>2.238806</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166281</td>\n",
       "      <td>1.956521</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1  0.000000  0.000000  0.000000   9.191265  0.000000  0.000000  2.301630   \n",
       "2  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          v9       v10        v11    ...         v120      v121      v122  \\\n",
       "0   9.999999  0.503281  16.434108    ...     1.059603  0.803572  8.000000   \n",
       "1   0.000000  1.312910   0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  12.666667  0.765864  14.756098    ...     2.138728  2.238806  9.333333   \n",
       "3   8.965516  6.542669  16.347483    ...     1.166281  1.956521  7.018256   \n",
       "4   0.000000  1.050328   0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\n",
       "       v123      v124      v126      v127      v128      v130      v131  \n",
       "0  1.989780  0.035754  1.804126  3.113719  2.024285  0.636365  2.857144  \n",
       "1  0.000000  0.598896  0.000000  0.000000  1.957825  0.000000  0.000000  \n",
       "2  2.477596  0.013452  1.773709  3.922193  1.120468  0.883118  1.176472  \n",
       "3  1.812795  0.002267  1.415230  2.954381  1.990847  1.677108  1.034483  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = data.loc[:, all_numerical_column_names].fillna(0)\n",
    "num_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(num_data, target, train_size=0.7, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142870697772592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_DT = DecisionTreeClassifier(max_depth=10)\n",
    "model_DT_cross = cross_val_score(model_DT, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_DT_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7507139286515775\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier со 100 деревьями\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_Bagging = BaggingClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_Bagging_cross = cross_val_score(model_Bagging, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Bagging_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier со 100 деревьями\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_Forest = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "model_Forest_cross = cross_val_score(model_Forest, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "# print(np.mean(model_Forest_cross))\n",
    "print(model_Forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Число деревьев в случайном лесе\n",
    "В этой задаче рассмотрим, переобучаются ли композиционные алгоритмы с увеличением числа деревьев.\n",
    "\n",
    "Переберем значения от 20 до 1000-5000 деревьев с шагом 50, посчитаем accuracy на тестовой выборке для каждого числа деревьев и построем график зависимости качества от числа деревьев.\n",
    "\n",
    "Рекомендация.\n",
    "\n",
    "Если каждый раз обучать RandomForest с нуля, придётся обучить в общей сумме $20 + 70 + \\ldots + 5000$ деревьев, но можно обучить всего 5000 деревьев.\n",
    "\n",
    "Для этого в при создании объекта класса RandomForestClassifier нужно указать в том числе warm_start=True. Затем обучить алгоритм с помощью метода fit, использовать метод predict для классификации. После этого с помощью метода set_params изменить параметр n_estimators. Если к полученному объекту применить метод fit, внутри него будет обучаться только недостающее число деревьев.\n",
    "\n",
    "Переобучается ли случайный лес с увеличением числа деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1111d8c50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe2bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trees_num = 1020\n",
    "model_Forest = RandomForestClassifier(max_depth=10, n_jobs=-1, warm_start=True)\n",
    "accuracies = []\n",
    "for i in range(20, trees_num, 10):\n",
    "    model_Forest.set_params(n_estimators=i)\n",
    "    # x_train, x_test, y_train, y_test\n",
    "    model_Forest.fit(x_train, y_train)\n",
    "    y_pred = model_Forest.predict(x_test)\n",
    "    r = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(r)\n",
    "\n",
    "plt.plot([i for i in range(20, trees_num, 10)], accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение градиентного бустинга\n",
    "\n",
    "А теперь попробуем обучить на тех же данных catboost — одну из реализаций градиентного бустинга. Подберем параметры на обучающем множестве с помощью кросс-валидации (хорошая [статья](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/) про тюнинг параметров). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.035602\n",
      "Learning rate set to 0.0356\n",
      "Learning rate set to 0.035602\n",
      "0.7595709902491885\n"
     ]
    }
   ],
   "source": [
    "model_Cat = CatBoostClassifier(iterations=700, verbose=False, thread_count=4)\n",
    "model_Cat_cross = cross_val_score(model_Cat, x_train, y_train, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "print(np.mean(model_Cat_cross))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вспомним, что изначально выбросили все категориальные признаки из датасета. Добавим категориальные признаки с количеством уникальных значений < 50 тремя способами:\n",
    "* как OHE признаки\n",
    "* как порядковые признаки (закодируйте с помощью LabelEncoder, порядок случайный)\n",
    "* как счетчики со сглаживанием\n",
    "\n",
    "Подберем в каждом из случаев оптимальные параметры метода. Должна ли меняться оптимальная глубина деревьев от способа кодирования категориальных признаков? Как меняется время, необходимое для обучения модели в зависимости от способа кодирования? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    108\n",
       "object      19\n",
       "int64        5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_NAME= 'train.csv'\n",
    "COUNT_OBJECTS = 10000\n",
    "data = pd.read_csv(FILE_NAME, nrows=COUNT_OBJECTS)\n",
    "\n",
    "target = data[\"target\"]\n",
    "data = data.drop([\"target\"], axis=1)\n",
    "\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_numerical_column_names = list(filter(lambda elem : data[elem].dtype == 'float64',  data.columns))\n",
    "all_int_column_names = list(filter(lambda elem : data[elem].dtype == 'int64',  data.columns))\n",
    "all_object_column_names = list(filter(lambda elem : data[elem].dtype == 'object',  data.columns))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
